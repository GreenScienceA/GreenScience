<h2>âš–ï¸ Test d'HypothÃ¨ses : Le Moteur de la DÃ©couverte Scientifique</h2>

<p>Imaginez que vous Ãªtes un agronome en AlgÃ©rie testant un nouvel engrais sur des champs de blÃ©. Vous l'appliquez Ã  30 parcelles sÃ©lectionnÃ©es au hasard et comparez leurs rendements Ã  30 parcelles tÃ©moins. Les parcelles traitÃ©es affichent en moyenne 4,2 tonnes/ha contre 3,8 tonnes/ha pour les tÃ©moins. Cette diffÃ©rence de 0,4 tonne est-elle <em>rÃ©elle</em> â€” un vÃ©ritable effet de l'engrais â€” ou aurait-elle pu survenir par pur hasard, simplement par la variation naturelle entre les champs ? C'est la question fondamentale pour laquelle le <strong>test d'hypothÃ¨ses</strong> a Ã©tÃ© inventÃ©.</p>

<p>Le test d'hypothÃ¨ses est le cadre statistique formel pour prendre des dÃ©cisions sous incertitude. Il transforme des questions scientifiques vagues (Â« Ce traitement fonctionne-t-il ? Â») en problÃ¨mes mathÃ©matiques prÃ©cis avec des taux d'erreur quantifiables. DÃ©veloppÃ© au dÃ©but du XXáµ‰ siÃ¨cle par trois gÃ©ants intellectuels â€” <strong>Ronald A. Fisher</strong>, <strong>Jerzy Neyman</strong> et <strong>Egon Pearson</strong> â€” il reste l'outil infÃ©rentiel le plus utilisÃ© en science, mÃ©decine, ingÃ©nierie et recherche sociale (Lehmann &amp; Romano, 2005).</p>

<blockquote>ğŸ’¡ <strong>Pourquoi le Test d'HypothÃ¨ses est Important :</strong> Sans cadre formel, les humains sont notoirement mauvais pour juger si des patterns sont rÃ©els ou coÃ¯ncidents. Le test d'hypothÃ¨ses fournit une mÃ©thode disciplinÃ©e et reproductible pour sÃ©parer les effets vÃ©ritables du bruit alÃ©atoire â€” nous protÃ©geant de nos propres biais cognitifs et permettant Ã  la science d'accumuler des connaissances fiables.</blockquote>

<hr>

<h2>ğŸ“œ Un Bref Historique : Trois Philosophies, Une ProcÃ©dure</h2>

<p>Ce que la plupart des manuels enseignent comme une procÃ©dure unifiÃ©e est en rÃ©alitÃ© une fusion malaisÃ©e de deux approches distinctes â€” et historiquement rivales (Lehmann, 1993). Comprendre cette histoire intellectuelle vous aide Ã  utiliser le test d'hypothÃ¨ses plus judicieusement.</p>

<h3>ğŸ£ Le Test de Signification de Fisher (1925)</h3>

<p>Ronald A. Fisher, travaillant Ã  la Station ExpÃ©rimentale de Rothamsted sur des expÃ©riences agricoles, a dÃ©veloppÃ© le <strong>test de signification</strong> comme mÃ©thode de quantification de l'Ã©vidence contre une hypothÃ¨se. Son innovation clÃ© fut la <strong>valeur p</strong> â€” une mesure continue de la surprise que les donnÃ©es causeraient si l'hypothÃ¨se nulle Ã©tait vraie (Fisher, 1925). Fisher considÃ©rait la valeur p comme un outil de <em>raisonnement inductif</em> : une petite valeur p constitue une preuve contre Hâ‚€, avec des valeurs plus petites indiquant une preuve plus forte. Il considÃ©rait 0,05 comme un simple point de rÃ©fÃ©rence pratique, et non un seuil mÃ©canique de dÃ©cision.</p>

<h3>âš™ï¸ La ThÃ©orie de DÃ©cision de Neyman-Pearson (1928â€“1933)</h3>

<p>Jerzy Neyman et Egon Pearson ont adoptÃ© une approche fondamentalement diffÃ©rente. Ils ont formulÃ© le test comme un <strong>problÃ¨me de dÃ©cision</strong> entre deux hypothÃ¨ses avec un contrÃ´le explicite des taux d'erreur Ã  long terme. Leurs innovations incluaient : l'<em>hypothÃ¨se alternative</em> formelle (Hâ‚), les <em>erreurs de Type I et Type II</em>, le concept de <em>puissance statistique</em>, et le <strong>lemme de Neyman-Pearson</strong> â€” qui identifie le test le plus puissant pour les hypothÃ¨ses simples (Neyman &amp; Pearson, 1933).</p>

<h3>ğŸ”€ L'Hybride Moderne : le NHST</h3>

<p>Ce que les chercheurs pratiquent aujourd'hui est le <strong>Test de Signification de l'HypothÃ¨se Nulle (NHST)</strong> â€” un amalgame qui mÃ©lange les valeurs p de Fisher avec le cadre dÃ©cisionnel de Neyman-Pearson (Gigerenzer, 2004). Vous formulez Hâ‚€ et Hâ‚, calculez une valeur p, la comparez Ã  un Î± prÃ©dÃ©fini, et parfois interprÃ©tez l'amplitude de la valeur p comme force de preuve.</p>

<table>
  <thead>
    <tr><th>CaractÃ©ristique</th><th>Fisher (1925)</th><th>Neyman-Pearson (1933)</th><th>NHST (Hybride Moderne)</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>HypothÃ¨ses</strong></td><td>Hâ‚€ seule</td><td>Hâ‚€ et Hâ‚ explicitement</td><td>Hâ‚€ et Hâ‚</td></tr>
    <tr><td><strong>MÃ©trique clÃ©</strong></td><td>Valeur p (continue)</td><td>Î± et Î² (prÃ©-fixÃ©s)</td><td>Valeur p comparÃ©e Ã  Î±</td></tr>
    <tr><td><strong>Objectif</strong></td><td>Mesurer l'Ã©vidence contre Hâ‚€</td><td>Minimiser les erreurs de dÃ©cision Ã  long terme</td><td>MÃ©lange des deux</td></tr>
    <tr><td><strong>DÃ©cision</strong></td><td>Pas de dÃ©cision binaire ; preuve graduÃ©e</td><td>Rejeter ou ne pas rejeter</td><td>Rejeter si p &lt; Î±</td></tr>
    <tr><td><strong>Puissance</strong></td><td>Non considÃ©rÃ©e formellement</td><td>Concept central (1 âˆ’ Î²)</td><td>Souvent nÃ©gligÃ©e en pratique</td></tr>
    <tr><td><strong>Philosophie</strong></td><td>InfÃ©rence inductive</td><td>Comportement inductif (contrÃ´le Ã  long terme)</td><td>MÃ©lange incohÃ©rent</td></tr>
  </tbody>
</table>

<hr>

<h2>ğŸ”¬ L'Anatomie d'un Test d'HypothÃ¨ses</h2>

<p>MalgrÃ© les diffÃ©rences philosophiques, le test d'hypothÃ¨ses moderne suit une procÃ©dure structurÃ©e en 7 Ã©tapes. Parcourons chaque Ã©tape avec notre exemple d'engrais pour blÃ©.</p>

<h3>Ã‰tape 1 : Formuler la Question de Recherche</h3>

<p>Traduisez votre question scientifique en une forme statistique testable. Notre question : Â« Le nouvel engrais augmente-t-il le rendement du blÃ© ? Â» Cela doit Ãªtre formulÃ© en termes de paramÃ¨tres de population, non de statistiques d'Ã©chantillon.</p>

<h3>Ã‰tape 2 : Formuler les HypothÃ¨ses</h3>

<p>Chaque test implique une paire d'hypothÃ¨ses mutuellement exclusives et exhaustives concernant un paramÃ¨tre de population Î¸ :</p>

<table>
  <thead>
    <tr><th>HypothÃ¨se</th><th>Symbole</th><th>Signification</th><th>Exemple Engrais</th></tr>
  </thead>
  <tbody>
    <tr><td>ğŸ”´ <strong>HypothÃ¨se Nulle</strong></td><td>Hâ‚€</td><td>L'Ã©noncÃ© Â« pas d'effet Â» ou Â« pas de diffÃ©rence Â» ; le statu quo</td><td>Hâ‚€ : Î¼â‚ âˆ’ Î¼â‚‚ = 0 (l'engrais n'a aucun effet)</td></tr>
    <tr><td>ğŸŸ¢ <strong>HypothÃ¨se Alternative</strong></td><td>Hâ‚ ou Hâ‚</td><td>L'affirmation que le chercheur souhaite soutenir ; contredit Hâ‚€</td><td>Hâ‚ : Î¼â‚ âˆ’ Î¼â‚‚ &gt; 0 (l'engrais augmente le rendement)</td></tr>
  </tbody>
</table>

<blockquote>ğŸ§  <strong>Insight ClÃ© :</strong> On ne Â« prouve Â» jamais Hâ‚ directement. On Ã©value plutÃ´t si les donnÃ©es fournissent suffisamment de preuves pour <em>rejeter</em> Hâ‚€. C'est la logique de la <strong>preuve par contradiction</strong> â€” on suppose que Hâ‚€ est vraie, on montre que les donnÃ©es sont hautement invraisemblables sous cette hypothÃ¨se, puis on conclut que Hâ‚€ est probablement fausse.</blockquote>

<h3>Tests UnilatÃ©raux vs. BilatÃ©raux</h3>

<table>
  <thead>
    <tr><th>Type</th><th>Forme de Hâ‚</th><th>Quand l'Utiliser</th><th>Exemple</th></tr>
  </thead>
  <tbody>
    <tr><td>â¡ï¸ <strong>UnilatÃ©ral droit</strong></td><td>Hâ‚ : Î¸ &gt; Î¸â‚€</td><td>Vous prÃ©disez une direction spÃ©cifique</td><td>L'engrais <em>augmente</em> le rendement</td></tr>
    <tr><td>â¬…ï¸ <strong>UnilatÃ©ral gauche</strong></td><td>Hâ‚ : Î¸ &lt; Î¸â‚€</td><td>Vous prÃ©disez une diminution</td><td>Le mÃ©dicament <em>rÃ©duit</em> la tension</td></tr>
    <tr><td>â†”ï¸ <strong>BilatÃ©ral</strong></td><td>Hâ‚ : Î¸ â‰  Î¸â‚€</td><td>Vous prÃ©disez une diffÃ©rence, pas sa direction</td><td>La mÃ©thode pÃ©dagogique <em>diffÃ¨re</em> de l'ancienne</td></tr>
  </tbody>
</table>

<p>Les tests bilatÃ©raux sont plus conservateurs (plus difficiles de rejeter Hâ‚€) car ils divisent Î± entre les deux queues. N'utilisez les tests unilatÃ©raux que lorsque vous avez une justification thÃ©orique <em>a priori</em> solide pour la direction â€” jamais parce que vous avez regardÃ© les donnÃ©es en premier (Lombardi &amp; Hurlbert, 2009).</p>

<h3>Ã‰tape 3 : Choisir le Seuil de Signification (Î±)</h3>

<p>Le seuil de signification Î± est la <strong>probabilitÃ© maximale d'une erreur de Type I</strong> que vous Ãªtes prÃªt Ã  tolÃ©rer. Il doit Ãªtre fixÃ© <em>avant</em> la collecte des donnÃ©es.</p>

<table>
  <thead>
    <tr><th>Niveau Î±</th><th>InterprÃ©tation</th><th>Usage Typique</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>0,10</strong></td><td>10 % de risque de fausse alarme ; plus libÃ©ral</td><td>Recherche exploratoire, Ã©tudes pilotes</td></tr>
    <tr><td><strong>0,05</strong></td><td>5 % de risque de fausse alarme ; convention par dÃ©faut</td><td>La plupart des disciplines scientifiques</td></tr>
    <tr><td><strong>0,01</strong></td><td>1 % de risque de fausse alarme ; plus strict</td><td>Essais mÃ©dicaux, dÃ©cisions Ã  haut enjeu</td></tr>
    <tr><td><strong>0,001</strong></td><td>0,1 % de risque ; trÃ¨s strict</td><td>GÃ©nomique, physique des particules</td></tr>
  </tbody>
</table>

<blockquote>âš ï¸ <strong>La Convention de 0,05 :</strong> L'utilisation quasi-universelle de Î± = 0,05 remonte Ã  la recommandation de Fisher en 1925. Bien que pratique, elle est fondamentalement arbitraire. Benjamin et al. (2018) ont proposÃ© de redÃ©finir la signification statistique Ã  p &lt; 0,005 pour les nouvelles dÃ©couvertes, arguant que le seuil de 0,05 produit trop de faux positifs.</blockquote>

<h3>Ã‰tape 4 : SÃ©lectionner la Statistique de Test</h3>

<p>La statistique de test transforme vos donnÃ©es en un nombre unique mesurant la dÃ©viation du rÃ©sultat par rapport Ã  ce que Hâ‚€ prÃ©dit :</p>

<table>
  <thead>
    <tr><th>Situation</th><th>Statistique de Test</th><th>Distribution Sous Hâ‚€</th></tr>
  </thead>
  <tbody>
    <tr><td>Moyenne, Ïƒ connu, grand n</td><td>z = (xÌ„ âˆ’ Î¼â‚€) / (Ïƒ/âˆšn)</td><td>Normale standard N(0,1)</td></tr>
    <tr><td>Moyenne, Ïƒ inconnu</td><td>t = (xÌ„ âˆ’ Î¼â‚€) / (s/âˆšn)</td><td>Student t avec ddl = nâˆ’1</td></tr>
    <tr><td>Deux moyennes indÃ©pendantes</td><td>t = (xÌ„â‚ âˆ’ xÌ„â‚‚) / SE</td><td>Student t avec ddl combinÃ©s</td></tr>
    <tr><td>Proportion</td><td>z = (pÌ‚ âˆ’ pâ‚€) / âˆš[pâ‚€(1âˆ’pâ‚€)/n]</td><td>Normale standard (grand n)</td></tr>
    <tr><td>Variance</td><td>Ï‡Â² = (nâˆ’1)sÂ² / Ïƒâ‚€Â²</td><td>Khi-deux avec ddl = nâˆ’1</td></tr>
    <tr><td>DonnÃ©es catÃ©gorielles</td><td>Ï‡Â² = Î£ (Oâˆ’E)Â² / E</td><td>Khi-deux</td></tr>
    <tr><td>Moyennes de plusieurs groupes</td><td>F = CM<sub>inter</sub> / CM<sub>intra</sub></td><td>Distribution F</td></tr>
  </tbody>
</table>

<h3>Ã‰tape 5 : DÃ©terminer la RÃ©gion Critique ou Calculer la Valeur p</h3>

<p><strong>Approche A â€” MÃ©thode de la Valeur Critique :</strong> Trouvez la valeur frontiÃ¨re qui sÃ©pare la rÃ©gion de rejet de la rÃ©gion de non-rejet. Si votre statistique de test tombe dans la rÃ©gion de rejet, rejetez Hâ‚€.</p>

<p><strong>Approche B â€” MÃ©thode de la Valeur p :</strong> Calculez la probabilitÃ© d'obtenir une statistique de test aussi extrÃªme que celle observÃ©e, en supposant Hâ‚€ vraie. Si p â‰¤ Î±, rejetez Hâ‚€. L'approche par la valeur p est plus informative car elle montre la force exacte de la preuve (Wasserstein &amp; Lazar, 2016).</p>

<h3>Ã‰tape 6 : Collecter les DonnÃ©es et Calculer</h3>

<p>Supposons que nos donnÃ©es donnent t<sub>obs</sub> = 2,31 avec p = 0,012. Puisque p = 0,012 &lt; Î± = 0,05, nous rejetons Hâ‚€.</p>

<h3>Ã‰tape 7 : Formuler la Conclusion</h3>

<p>Traduisez toujours dans le contexte rÃ©el : Â« Il existe une preuve statistiquement significative au seuil de 5 % que le nouvel engrais augmente le rendement du blÃ© (t(58) = 2,31, p = 0,012, d = 0,60). Â» Rapportez la statistique de test, les degrÃ©s de libertÃ©, la valeur p <em>et</em> une taille d'effet (Wilkinson &amp; Task Force, 1999).</p>

<hr>

<h2>ğŸš¨ Erreurs de Type I et de Type II : Les Deux FaÃ§ons de Se Tromper</h2>

<table>
  <thead>
    <tr><th></th><th>Hâ‚€ est RÃ©ellement VRAIE</th><th>Hâ‚€ est RÃ©ellement FAUSSE</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>Rejeter Hâ‚€</strong></td><td>ğŸ”´ <strong>Erreur de Type I</strong> (Faux Positif) â€” ProbabilitÃ© = Î±</td><td>âœ… <strong>DÃ©cision Correcte</strong> (Vrai Positif) â€” ProbabilitÃ© = 1 âˆ’ Î² = Puissance</td></tr>
    <tr><td><strong>Ne pas rejeter Hâ‚€</strong></td><td>âœ… <strong>DÃ©cision Correcte</strong> (Vrai NÃ©gatif) â€” ProbabilitÃ© = 1 âˆ’ Î±</td><td>ğŸŸ¡ <strong>Erreur de Type II</strong> (Faux NÃ©gatif) â€” ProbabilitÃ© = Î²</td></tr>
  </tbody>
</table>

<h3>ğŸ”´ Erreur de Type I (Î±) â€” La Fausse Alarme</h3>

<p>Vous concluez que l'engrais fonctionne alors qu'en rÃ©alitÃ© il n'a aucun effet. En recherche mÃ©dicale, cela pourrait signifier approuver un mÃ©dicament inefficace ; en justice pÃ©nale, c'est condamner un innocent.</p>

<h3>ğŸŸ¡ Erreur de Type II (Î²) â€” La DÃ©couverte ManquÃ©e</h3>

<p>Vous Ã©chouez Ã  dÃ©tecter que l'engrais fonctionne rÃ©ellement. En mÃ©decine, cela signifie ne pas identifier un traitement efficace.</p>

<blockquote>ğŸ›ï¸ <strong>L'Analogie du Tribunal :</strong> En droit pÃ©nal, l'hypothÃ¨se nulle est Â« l'accusÃ© est innocent Â». Une erreur de Type I est <em>condamner un innocent</em> (faux positif) â€” le systÃ¨me judiciaire est conÃ§u pour rendre cela rare (Â« au-delÃ  de tout doute raisonnable Â»). Une erreur de Type II est <em>acquitter un coupable</em> (faux nÃ©gatif) â€” regrettable, mais considÃ©rÃ© comme moins catastrophique.</blockquote>

<h3>Le Compromis Î±â€“Î²</h3>

<p>Pour un Ã©chantillon de taille fixe, diminuer Î± augmente inÃ©vitablement Î². La seule faÃ§on de rÃ©duire les <em>deux</em> erreurs simultanÃ©ment est d'<strong>augmenter la taille de l'Ã©chantillon</strong> â€” plus de donnÃ©es donnent plus de prÃ©cision (Cohen, 1988).</p>

<hr>

<h2>ğŸ’ª Puissance Statistique : La CapacitÃ© de DÃ©tecter le RÃ©el</h2>

<p>La <strong>puissance statistique</strong> est la probabilitÃ© qu'un test rejette correctement Hâ‚€ quand Hâ‚ est vraie. Elle vaut 1 âˆ’ Î².</p>

<table>
  <thead>
    <tr><th>Facteur</th><th>Effet sur la Puissance</th><th>Pourquoi</th></tr>
  </thead>
  <tbody>
    <tr><td>ğŸ“ˆ <strong>Taille d'effet plus grande</strong></td><td>â†‘ Augmente</td><td>Les effets plus importants sont plus faciles Ã  dÃ©tecter</td></tr>
    <tr><td>ğŸ“Š <strong>Taille d'Ã©chantillon plus grande (n)</strong></td><td>â†‘ Augmente</td><td>Plus de donnÃ©es rÃ©duit la variabilitÃ© d'Ã©chantillonnage</td></tr>
    <tr><td>ğŸ¯ <strong>Î± plus Ã©levÃ©</strong></td><td>â†‘ Augmente</td><td>Seuil plus bas pour le rejet (mais augmente l'erreur de Type I)</td></tr>
    <tr><td>ğŸ“‰ <strong>VariabilitÃ© plus faible (Ïƒ)</strong></td><td>â†‘ Augmente</td><td>Moins de bruit rend le signal plus clair</td></tr>
    <tr><td>â¡ï¸ <strong>UnilatÃ©ral vs. bilatÃ©ral</strong></td><td>â†‘ UnilatÃ©ral a plus de puissance</td><td>Concentre Î± dans une direction</td></tr>
  </tbody>
</table>

<blockquote>ğŸ¯ <strong>La Convention de 80 % :</strong> Cohen (1988) a recommandÃ© que les Ã©tudes soient conÃ§ues pour atteindre au moins 80 % de puissance (Î² â‰¤ 0,20). Pourtant, des enquÃªtes empiriques montrent que la puissance mÃ©diane dans la recherche publiÃ©e est bien infÃ©rieure â€” environ 50 % ou moins dans de nombreux domaines (Button et al., 2013). Cette Â« dÃ©faillance de puissance Â» est un contributeur majeur Ã  la crise de rÃ©plication.</blockquote>

<hr>

<h2>ğŸ“ La Valeur p : Ce Qu'elle Est et Ce Qu'elle N'est PAS</h2>

<p>La <strong>valeur p</strong> est peut-Ãªtre la statistique la plus utilisÃ©e, la plus mal comprise et la plus controversÃ©e de toute la science. En 2016, l'American Statistical Association (ASA) a pris la mesure sans prÃ©cÃ©dent de publier une dÃ©claration formelle sur son utilisation correcte (Wasserstein &amp; Lazar, 2016).</p>

<h3>âœ… Ce Que la Valeur p EST</h3>

<p>La valeur p est la probabilitÃ©, <strong>en supposant Hâ‚€ vraie</strong>, d'obtenir une statistique de test aussi extrÃªme ou plus extrÃªme que celle observÃ©e :</p>

<p style="text-align: center; font-size: 1.1em;"><strong>p = P(T â‰¥ t<sub>obs</sub> | Hâ‚€ est vraie)</strong></p>

<h3>âŒ Ce Que la Valeur p N'est PAS</h3>

<table>
  <thead>
    <tr><th>IdÃ©e Fausse Courante</th><th>RÃ©alitÃ©</th></tr>
  </thead>
  <tbody>
    <tr><td>Â« p = 0,03 signifie 3 % de chance que Hâ‚€ soit vraie Â»</td><td>âŒ La valeur p est P(donnÃ©es | Hâ‚€), <strong>PAS</strong> P(Hâ‚€ | donnÃ©es).</td></tr>
    <tr><td>Â« p = 0,03 signifie 97 % de chance que l'effet soit rÃ©el Â»</td><td>âŒ MÃªme erreur inversÃ©e. On ne peut pas dÃ©river P(Hâ‚ | donnÃ©es) de la valeur p seule.</td></tr>
    <tr><td>Â« Un p plus petit signifie un effet plus grand Â»</td><td>âŒ La valeur p mÃ©lange taille d'effet et taille d'Ã©chantillon.</td></tr>
    <tr><td>Â« p &gt; 0,05 signifie qu'il n'y a pas d'effet Â»</td><td>âŒ <strong>L'absence de preuve n'est pas la preuve de l'absence</strong> (Altman &amp; Bland, 1995).</td></tr>
    <tr><td>Â« p = 0,049 est fondamentalement diffÃ©rent de p = 0,051 Â»</td><td>âŒ La diffÃ©rence entre Â« significatif Â» et Â« non significatif Â» n'est pas elle-mÃªme significative (Gelman &amp; Stern, 2006).</td></tr>
  </tbody>
</table>

<blockquote>ğŸ“¢ <strong>Les Six Principes de l'ASA (Wasserstein &amp; Lazar, 2016) :</strong><br>
1. Les valeurs p peuvent indiquer une incompatibilitÃ© entre les donnÃ©es et un modÃ¨le spÃ©cifiÃ©.<br>
2. Les valeurs p ne mesurent pas la probabilitÃ© que l'hypothÃ¨se soit vraie.<br>
3. Les conclusions scientifiques ne doivent pas reposer uniquement sur un seuil de valeur p.<br>
4. Une infÃ©rence correcte exige un rapport complet et transparent.<br>
5. La valeur p ne mesure pas la taille d'un effet ni l'importance d'un rÃ©sultat.<br>
6. En soi, une valeur p ne fournit pas une bonne mesure de preuve.</blockquote>

<hr>

<h2>ğŸ“ Taille d'Effet : La Magnitude Qui Compte</h2>

<p>Si la valeur p rÃ©pond Ã  Â« Y a-t-il un effet ? Â», la <strong>taille d'effet</strong> rÃ©pond Ã  la question bien plus importante : Â« <strong>Quelle est l'ampleur de l'effet ?</strong> Â»</p>

<table>
  <thead>
    <tr><th>Mesure</th><th>Formule</th><th>Usage</th><th>RepÃ¨res de Cohen</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>d de Cohen</strong></td><td>d = (xÌ„â‚ âˆ’ xÌ„â‚‚) / s<sub>combinÃ©</sub></td><td>DiffÃ©rence entre deux moyennes</td><td>Petit : 0,2 | Moyen : 0,5 | Grand : 0,8</td></tr>
    <tr><td><strong>r de Pearson</strong></td><td>Coefficient de corrÃ©lation</td><td>Force d'association</td><td>Petit : 0,1 | Moyen : 0,3 | Grand : 0,5</td></tr>
    <tr><td><strong>Î·Â² (ÃŠta carrÃ©)</strong></td><td>SC<sub>effet</sub> / SC<sub>total</sub></td><td>Proportion de variance expliquÃ©e (ANOVA)</td><td>Petit : 0,01 | Moyen : 0,06 | Grand : 0,14</td></tr>
    <tr><td><strong>fÂ² de Cohen</strong></td><td>RÂ² / (1 âˆ’ RÂ²)</td><td>Taille d'effet en rÃ©gression</td><td>Petit : 0,02 | Moyen : 0,15 | Grand : 0,35</td></tr>
    <tr><td><strong>Odds Ratio (OR)</strong></td><td>ad / bc</td><td>Issues catÃ©gorielles</td><td>Petit : 1,5 | Moyen : 2,5 | Grand : 4,3</td></tr>
  </tbody>
</table>

<blockquote>ğŸ’¬ <strong>La Sagesse de Jacob Cohen :</strong> Â« Le produit principal d'une enquÃªte de recherche est une ou plusieurs mesures de taille d'effet, pas des valeurs p. Â» (Cohen, 1990). Rapportez toujours les tailles d'effet en plus des valeurs p.</blockquote>

<hr>

<h2>ğŸ”„ Le Flux de Travail Complet du Test d'HypothÃ¨ses</h2>

<table>
  <thead>
    <tr><th>Ã‰tape</th><th>Action</th><th>Question ClÃ©</th></tr>
  </thead>
  <tbody>
    <tr><td>1ï¸âƒ£</td><td>DÃ©finir la question de recherche</td><td>Quel effet ou relation est-ce que je teste ?</td></tr>
    <tr><td>2ï¸âƒ£</td><td>Formuler Hâ‚€ et Hâ‚</td><td>Quelle est l'hypothÃ¨se nulle vs. alternative ?</td></tr>
    <tr><td>3ï¸âƒ£</td><td>Fixer Î± (ex. 0,05)</td><td>Quel risque d'erreur de Type I est-ce que j'accepte ?</td></tr>
    <tr><td>4ï¸âƒ£</td><td>Analyse de puissance a priori</td><td>De combien de sujets/observations ai-je besoin ?</td></tr>
    <tr><td>5ï¸âƒ£</td><td>Collecter les donnÃ©es</td><td>Mon plan d'Ã©chantillonnage est-il valide et non biaisÃ© ?</td></tr>
    <tr><td>6ï¸âƒ£</td><td>VÃ©rifier les hypothÃ¨ses</td><td>NormalitÃ© ? Variances Ã©gales ? IndÃ©pendance ?</td></tr>
    <tr><td>7ï¸âƒ£</td><td>Calculer la statistique de test et la valeur p</td><td>Les donnÃ©es sont-elles extrÃªmes sous Hâ‚€ ?</td></tr>
    <tr><td>8ï¸âƒ£</td><td>Prendre la dÃ©cision</td><td>Est-ce que p â‰¤ Î± ? Rejeter ou ne pas rejeter Hâ‚€</td></tr>
    <tr><td>9ï¸âƒ£</td><td>Rapporter la taille d'effet et l'IC</td><td>Quelle est l'ampleur et la prÃ©cision de l'effet ?</td></tr>
    <tr><td>ğŸ”Ÿ</td><td>InterprÃ©ter en contexte</td><td>Que signifie cela pour mon domaine ?</td></tr>
  </tbody>
</table>

<hr>

<h2>âš ï¸ PiÃ¨ges Courants et Bonnes Pratiques</h2>

<h3>PiÃ¨ges Ã  Ã‰viter</h3>

<table>
  <thead>
    <tr><th>PiÃ¨ge</th><th>Description</th><th>ConsÃ©quence</th></tr>
  </thead>
  <tbody>
    <tr><td>ğŸ£ <strong>p-Hacking</strong></td><td>ExÃ©cuter de multiples tests, sÃ©lectionner les rÃ©sultats favorables, supprimer des points de donnÃ©es gÃªnants jusqu'Ã  obtenir p &lt; 0,05</td><td>Taux de faux positifs gonflÃ© ; rÃ©sultats non rÃ©plicables</td></tr>
    <tr><td>ğŸ—‚ï¸ <strong>HARKing</strong></td><td>Formuler des hypothÃ¨ses aprÃ¨s avoir connu les rÃ©sultats â€” prÃ©senter des rÃ©sultats exploratoires comme confirmatoires</td><td>Biais de confirmation dÃ©guisÃ© en science rigoureuse</td></tr>
    <tr><td>ğŸ“‚ <strong>Biais de Publication</strong></td><td>Les revues publient prÃ©fÃ©rentiellement les rÃ©sultats significatifs (le Â« problÃ¨me du tiroir Â»)</td><td>La littÃ©rature publiÃ©e surestime les tailles d'effet</td></tr>
    <tr><td>ğŸ“Š <strong>Ignorer la Taille d'Effet</strong></td><td>Rapporter seulement Â« significatif Â» ou Â« non significatif Â» sans quantifier l'ampleur</td><td>Effets triviaux surÃ©valuÃ©s ; effets importants non significatifs Ã©cartÃ©s</td></tr>
    <tr><td>ğŸ”‹ <strong>Faible Puissance</strong></td><td>Ã‰tudes sous-puissancÃ©es (petits Ã©chantillons pour l'effet attendu)</td><td>Taux Ã©levÃ© d'erreur de Type II</td></tr>
    <tr><td>ğŸ” <strong>Comparaisons Multiples</strong></td><td>Effectuer de nombreux tests sans corriger Î±</td><td>Le taux d'erreur familial explose</td></tr>
  </tbody>
</table>

<h3>Bonnes Pratiques</h3>

<table>
  <thead>
    <tr><th>Pratique</th><th>Pourquoi C'est Important</th></tr>
  </thead>
  <tbody>
    <tr><td>ğŸ“ <strong>PrÃ©-enregistrer hypothÃ¨ses et plan d'analyse</strong></td><td>EmpÃªche le p-hacking et le HARKing</td></tr>
    <tr><td>ğŸ“ <strong>Toujours rapporter tailles d'effet et intervalles de confiance</strong></td><td>Fournit la signification pratique au-delÃ  du binaire de la valeur p</td></tr>
    <tr><td>ğŸ”‹ <strong>Analyse de puissance a priori</strong></td><td>Assure une taille d'Ã©chantillon adÃ©quate</td></tr>
    <tr><td>ğŸ”¢ <strong>Corriger pour les comparaisons multiples</strong></td><td>ContrÃ´le l'erreur familiale (Bonferroni, Holm, Benjamini-Hochberg)</td></tr>
    <tr><td>ğŸ“Š <strong>Rapporter les valeurs p exactes</strong></td><td>Dites Â« p = 0,032 Â» et non simplement Â« p &lt; 0,05 Â»</td></tr>
    <tr><td>ğŸ”„ <strong>RÃ©pliquer les rÃ©sultats</strong></td><td>Une seule Ã©tude n'est jamais dÃ©finitive</td></tr>
    <tr><td>ğŸ“ˆ <strong>ConsidÃ©rer les alternatives bayÃ©siennes</strong></td><td>Les mÃ©thodes bayÃ©siennes peuvent quantifier la preuve <em>pour</em> Hâ‚€</td></tr>
  </tbody>
</table>

<hr>

<h2>ğŸŒ Application ConcrÃ¨te : Un Exemple Complet</h2>

<p><strong>Question de Recherche :</strong> Un nouveau systÃ¨me d'irrigation goutte-Ã -goutte rÃ©duit-il la consommation d'eau dans la culture de tomates par rapport Ã  l'irrigation traditionnelle par submersion ?</p>

<p><strong>DonnÃ©es :</strong> 25 parcelles avec irrigation goutte-Ã -goutte (consommation moyenne = 4 200 mÂ³/ha, s = 380) vs. 25 parcelles avec submersion (moyenne = 5 100 mÂ³/ha, s = 420).</p>

<table>
  <thead>
    <tr><th>Ã‰tape</th><th>Application</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>Hâ‚€</strong></td><td>Î¼<sub>goutte</sub> âˆ’ Î¼<sub>submersion</sub> = 0</td></tr>
    <tr><td><strong>Hâ‚</strong></td><td>Î¼<sub>goutte</sub> âˆ’ Î¼<sub>submersion</sub> &lt; 0 (unilatÃ©ral gauche)</td></tr>
    <tr><td><strong>Î±</strong></td><td>0,05</td></tr>
    <tr><td><strong>Test</strong></td><td>Test t pour deux Ã©chantillons indÃ©pendants</td></tr>
    <tr><td><strong>SE</strong></td><td>âˆš(380Â²/25 + 420Â²/25) â‰ˆ 113,3</td></tr>
    <tr><td><strong>t<sub>obs</sub></strong></td><td>(4200 âˆ’ 5100) / 113,3 â‰ˆ âˆ’7,94</td></tr>
    <tr><td><strong>Valeur p</strong></td><td>p â‰ˆ 0,0000000001 (extrÃªmement faible)</td></tr>
    <tr><td><strong>Taille d'effet</strong></td><td>d â‰ˆ 2,25 (trÃ¨s grand)</td></tr>
    <tr><td><strong>DÃ©cision</strong></td><td>Rejeter Hâ‚€ â€” preuve Ã©crasante que l'irrigation goutte-Ã -goutte rÃ©duit la consommation d'eau</td></tr>
    <tr><td><strong>InterprÃ©tation</strong></td><td>L'irrigation goutte-Ã -goutte a rÃ©duit la consommation d'eau d'environ 900 mÂ³/ha (rÃ©duction de 17,6 %), avec une taille d'effet trÃ¨s grande (d = 2,25). Cela reprÃ©sente une Ã©conomie d'eau significative pour l'agriculture algÃ©rienne.</td></tr>
  </tbody>
</table>

<hr>

<h2>ğŸ§­ Au-delÃ  du NHST : Le Paysage Moderne</h2>

<table>
  <thead>
    <tr><th>Approche</th><th>IdÃ©e ClÃ©</th><th>Avantage par Rapport au NHST</th></tr>
  </thead>
  <tbody>
    <tr><td>ğŸ”µ <strong>Intervalles de Confiance</strong></td><td>Estimer la plage de valeurs plausibles du paramÃ¨tre</td><td>Montre prÃ©cision et direction, pas seulement la signification</td></tr>
    <tr><td>ğŸŸ£ <strong>Test BayÃ©sien d'HypothÃ¨ses</strong></td><td>Les facteurs de Bayes quantifient la preuve pour Hâ‚€ <em>et</em> Hâ‚</td><td>Peut soutenir Hâ‚€ ; intÃ¨gre les connaissances prÃ©alables</td></tr>
    <tr><td>ğŸŸ¢ <strong>Test d'Ã‰quivalence</strong></td><td>La procÃ©dure TOST teste si les effets sont nÃ©gligeables</td><td>Peut conclure affirmativement Â« pas d'effet significatif Â»</td></tr>
    <tr><td>ğŸŸ¡ <strong>MÃ©ta-Analyse</strong></td><td>Combine les rÃ©sultats de plusieurs Ã©tudes</td><td>Estimations plus prÃ©cises ; rÃ©duit le biais de publication</td></tr>
    <tr><td>ğŸ”´ <strong>PrÃ©-Enregistrement</strong></td><td>Enregistrer hypothÃ¨ses et mÃ©thodes avant la collecte</td><td>Ã‰limine le p-hacking et le HARKing</td></tr>
  </tbody>
</table>

<blockquote>ğŸ”® <strong>L'Avenir de l'InfÃ©rence :</strong> La tendance en statistique moderne n'est pas d'abandonner le test d'hypothÃ¨ses mais de l'<em>enrichir</em> â€” en combinant valeurs p, tailles d'effet, intervalles de confiance et mesures bayÃ©siennes pour construire un tableau plus complet de la preuve.</blockquote>

<hr>

<h2>ğŸ“š RÃ©fÃ©rences</h2>

<p>Altman, D. G., &amp; Bland, J. M. (1995). Absence of evidence is not evidence of absence. <em>BMJ</em>, 311(7003), 485. https://doi.org/10.1136/bmj.311.7003.485</p>

<p>Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., ... &amp; Johnson, V. E. (2018). Redefine statistical significance. <em>Nature Human Behaviour</em>, 2(1), 6â€“10. https://doi.org/10.1038/s41562-017-0189-z</p>

<p>Button, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S. J., &amp; MunafÃ², M. R. (2013). Power failure: Why small sample size undermines the reliability of neuroscience. <em>Nature Reviews Neuroscience</em>, 14(5), 365â€“376. https://doi.org/10.1038/nrn3475</p>

<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Lawrence Erlbaum Associates.</p>

<p>Cohen, J. (1990). Things I have learned (so far). <em>American Psychologist</em>, 45(12), 1304â€“1312. https://doi.org/10.1037/0003-066X.45.12.1304</p>

<p>Cumming, G. (2014). The new statistics: Why and how. <em>Psychological Science</em>, 25(1), 7â€“29. https://doi.org/10.1177/0956797613504966</p>

<p>Fisher, R. A. (1925). <em>Statistical methods for research workers</em>. Oliver and Boyd.</p>

<p>Gelman, A., &amp; Stern, H. (2006). The difference between "significant" and "not significant" is not itself statistically significant. <em>The American Statistician</em>, 60(4), 328â€“331. https://doi.org/10.1198/000313006X152649</p>

<p>Gigerenzer, G. (2004). Mindless statistics. <em>The Journal of Socio-Economics</em>, 33(5), 587â€“606. https://doi.org/10.1016/j.socec.2004.09.033</p>

<p>Lehmann, E. L. (1993). The Fisher, Neyman-Pearson theories of testing hypotheses: One theory or two? <em>Journal of the American Statistical Association</em>, 88(424), 1242â€“1249. https://doi.org/10.1080/01621459.1993.10476404</p>

<p>Lehmann, E. L., &amp; Romano, J. P. (2005). <em>Testing statistical hypotheses</em> (3rd ed.). Springer.</p>

<p>Lombardi, C. M., &amp; Hurlbert, S. H. (2009). Misprescription and misuse of oneâ€tailed tests. <em>Austral Ecology</em>, 34(4), 447â€“468. https://doi.org/10.1111/j.1442-9993.2009.01946.x</p>

<p>Moore, D. S., McCabe, G. P., &amp; Craig, B. A. (2021). <em>Introduction to the practice of statistics</em> (10th ed.). W.H. Freeman.</p>

<p>Neyman, J., &amp; Pearson, E. S. (1933). On the problem of the most efficient tests of statistical hypotheses. <em>Philosophical Transactions of the Royal Society A</em>, 231(694â€“706), 289â€“337. https://doi.org/10.1098/rsta.1933.0009</p>

<p>Wasserstein, R. L., &amp; Lazar, N. A. (2016). The ASA's statement on p-values: Context, process, and purpose. <em>The American Statistician</em>, 70(2), 129â€“133. https://doi.org/10.1080/00031305.2016.1154108</p>

<p>Wilkinson, L., &amp; the Task Force on Statistical Inference. (1999). Statistical methods in psychology journals: Guidelines and explanations. <em>American Psychologist</em>, 54(8), 594â€“604. https://doi.org/10.1037/0003-066X.54.8.594</p>
