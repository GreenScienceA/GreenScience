<h2>ğŸ“ˆ ANOVA : DissÃ©quer la Variance pour DÃ©couvrir la VÃ©ritÃ©</h2>

<p>Nous sommes en 1919 Ã  Harpenden, en Angleterre. Un jeune mathÃ©maticien nommÃ© <strong>Ronald Aylmer Fisher</strong> â€” Ã  peine 29 ans, sans poste formel et une famille Ã  nourrir â€” accepte un emploi temporaire Ã  la <strong>Station expÃ©rimentale de Rothamsted</strong>, le plus ancien centre de recherche agricole au monde. Sa mission : donner un sens Ã  70 annÃ©es de donnÃ©es agronomiques accumulÃ©es que personne n'avait su correctement analyser. Le directeur, Sir John Russell, reconnut rapidement qu'il Ã©tait Â« plus qu'un homme de grande capacitÃ© ; c'Ã©tait en fait un gÃ©nie qu'il fallait garder Â» (Russell, 1966, p. 327). En cinq ans, Fisher allait inventer la mÃ©thode statistique la plus utilisÃ©e de toute la science expÃ©rimentale â€” l'<strong>Analyse de la Variance</strong>, ou <strong>ANOVA</strong>.</p>

<p>L'ANOVA rÃ©pond Ã  une question d'apparence simple : <em>Les moyennes de trois groupes ou plus sont-elles vraiment diffÃ©rentes, ou les diffÃ©rences observÃ©es pourraient-elles Ãªtre expliquÃ©es par le seul hasard ?</em> Mais derriÃ¨re cette question se cache une idÃ©e parmi les plus Ã©lÃ©gantes de toute la statistique â€” l'idÃ©e que la <strong>variabilitÃ© totale peut Ãªtre partitionnÃ©e en composantes significatives</strong>, chacune attribuable Ã  une source diffÃ©rente. L'intuition de Fisher : au lieu de comparer les moyennes directement (ce qui devient ingÃ©rable avec plusieurs groupes), on compare les <em>variances</em> â€” la variance inter-groupes contre la variance intra-groupes â€” et le rapport de ces deux quantitÃ©s dit tout ce qu'il faut savoir (Fisher, 1925).</p>

<blockquote>ğŸ’¡ <strong>L'idÃ©e centrale :</strong> L'ANOVA ne compare pas des moyennes â€” elle compare des <em>variances</em>. Si la variance <em>entre</em> les groupes est beaucoup plus grande que la variance <em>Ã  l'intÃ©rieur</em> des groupes, alors les moyennes des groupes sont nÃ©cessairement diffÃ©rentes. Cette approche par rapport de variances â€” le test F â€” est le cÅ“ur battant de l'ANOVA et le fondement de pratiquement tout le design expÃ©rimental en science.</blockquote>

<hr>

<h2>ğŸŒ¾ Origines historiques : Comment les champs de blÃ© ont donnÃ© naissance Ã  la statistique moderne</h2>

<h3>Fisher Ã  Rothamsted (1919â€“1933)</h3>

<p>Lorsque Fisher arriva Ã  Rothamsted en 1919, la station menait des expÃ©riences agricoles continues depuis 1843 â€” la cÃ©lÃ¨bre expÃ©rience de Broadbalk sur le blÃ©, toujours en cours aujourd'hui, est la plus longue expÃ©rience agricole continue au monde (LangkjÃ¦r-Bain, 2018). La station possÃ©dait des montagnes de donnÃ©es sur les rendements, les engrais et les conditions mÃ©tÃ©orologiques, mais les chercheurs manquaient d'outils mathÃ©matiques pour en extraire des conclusions fiables.</p>

<p>La premiÃ¨re percÃ©e de Fisher fut un article de 1923 avec Winifred Mackenzie, Â« Studies in Crop Variation II Â», analysant les rendements de pommes de terre selon diffÃ©rentes variÃ©tÃ©s et traitements de fumure. Dans cet article, il introduisit la <strong>partition des sommes des carrÃ©s</strong> â€” l'opÃ©ration fondamentale de l'ANOVA â€” montrant comment la variation totale du rendement pouvait Ãªtre dÃ©composÃ©e en composantes dues Ã  la variÃ©tÃ©, au traitement et Ã  l'erreur rÃ©siduelle (Fisher &amp; Mackenzie, 1923). Cette partition fut formalisÃ©e dans le fameux <strong>tableau d'ANOVA</strong> et publiÃ©e systÃ©matiquement dans l'ouvrage pionnier de Fisher, <em>Statistical Methods for Research Workers</em> (1925), qui connut 14 Ã©ditions et demeure probablement le manuel de statistique le plus influent jamais Ã©crit.</p>

<p>En 1935, Fisher publia <em>The Design of Experiments</em>, qui introduisit les trois principes fondamentaux du plan expÃ©rimental â€” <strong>randomisation</strong>, <strong>rÃ©pÃ©tition</strong> et <strong>blocage</strong> â€” ainsi que les plans factoriels et la cÃ©lÃ¨bre expÃ©rience de pensÃ©e Â« The Lady Tasting Tea Â», premiÃ¨re formulation formelle de l'hypothÃ¨se nulle (Fisher, 1935).</p>

<blockquote>ğŸ§  <strong>L'humilitÃ© d'un statisticien :</strong> Fisher dÃ©crivit l'ANOVA comme simplement Â« une mÃ©thode simple pour arranger les faits arithmÃ©tiques de maniÃ¨re Ã  isoler et prÃ©senter les caractÃ©ristiques essentielles d'un ensemble de donnÃ©es avec la plus grande simplicitÃ©. Â» Richard Mead de Rothamsted l'a qualifiÃ©e de Â« probablement la chose la plus importante jamais sortie de Rothamsted du point de vue statistique, car c'est l'outil quotidien de la plupart des scientifiques Â» (LangkjÃ¦r-Bain, 2018).</blockquote>

<hr>

<h2>ğŸ”¬ La logique fondamentale : Pourquoi comparer des variances plutÃ´t que des moyennes ?</h2>

<h3>Le problÃ¨me des comparaisons multiples</h3>

<p>Supposons que vous soyez agronome Ã  SÃ©tif, en AlgÃ©rie, testant trois traitements fertilisants (A, B, C) sur le rendement du blÃ©. Votre premier rÃ©flexe serait de rÃ©aliser trois tests t distincts : A vs B, A vs C, et B vs C. Le problÃ¨me ? Chaque test t comporte un risque d'erreur de Type I de 5 %. Avec trois tests, votre risque global d'erreur passe Ã  environ 1 âˆ’ (1 âˆ’ 0,05)Â³ â‰ˆ 14,3 %. Avec 10 groupes, il faudrait 45 comparaisons et le risque atteindrait environ 90 % â€” ce qui garantit pratiquement de trouver au moins une diffÃ©rence fictive mÃªme quand aucune n'existe (Maxwell &amp; Delaney, 2004).</p>

<p>L'ANOVA rÃ©sout ce problÃ¨me en effectuant un seul <strong>test omnibus</strong> qui Ã©value toutes les moyennes simultanÃ©ment tout en maintenant le taux d'erreur de Type I au niveau Î± choisi (typiquement 0,05).</p>

<h3>La partition de la variance</h3>

<p>Le gÃ©nie de l'ANOVA rÃ©side dans la dÃ©composition de la variabilitÃ© totale en composantes additives :</p>

<p style="text-align:center; font-size:1.1em;"><strong>SS<sub>Total</sub> = SS<sub>Inter</sub> + SS<sub>Intra</sub></strong></p>

<p><strong>SS<sub>Inter</sub></strong> (ou SS<sub>Traitement</sub>) mesure combien les <em>moyennes des groupes</em> s'Ã©cartent de la moyenne gÃ©nÃ©rale â€” c'est la variabilitÃ© <em>expliquÃ©e</em> par le facteur.</p>

<p><strong>SS<sub>Intra</sub></strong> (ou SS<sub>Erreur</sub>) mesure combien les observations individuelles s'Ã©cartent de leur propre moyenne de groupe â€” c'est la variabilitÃ© <em>inexpliquÃ©e</em> ou alÃ©atoire.</p>

<h3>Le rapport F de Fisher</h3>

<p>Chaque somme des carrÃ©s est convertie en un <strong>carrÃ© moyen</strong> (CM) en divisant par ses degrÃ©s de libertÃ© :</p>

<table>
  <thead>
    <tr><th>Source</th><th>SS</th><th>ddl</th><th>CM</th><th>F</th></tr>
  </thead>
  <tbody>
    <tr><td>Inter-groupes</td><td>SS<sub>Inter</sub></td><td>k âˆ’ 1</td><td>SS<sub>Inter</sub> / (k âˆ’ 1)</td><td rowspan="2" style="vertical-align:middle"><strong>CM<sub>Inter</sub> / CM<sub>Intra</sub></strong></td></tr>
    <tr><td>Intra-groupes</td><td>SS<sub>Intra</sub></td><td>N âˆ’ k</td><td>SS<sub>Intra</sub> / (N âˆ’ k)</td></tr>
    <tr><td>Total</td><td>SS<sub>Total</sub></td><td>N âˆ’ 1</td><td>â€”</td><td>â€”</td></tr>
  </tbody>
</table>

<p>Le <strong>rapport F</strong> = CM<sub>Inter</sub> / CM<sub>Intra</sub> suit la <strong>distribution F</strong> avec (k âˆ’ 1, N âˆ’ k) degrÃ©s de libertÃ© sous l'hypothÃ¨se nulle. De grandes valeurs de F indiquent que les moyennes des groupes diffÃ¨rent davantage que ne le prÃ©dirait la seule variation alÃ©atoire (Fisher, 1925).</p>

<hr>

<h2>ğŸ“Š ANOVA Ã  un facteur : Exemple complet pas Ã  pas</h2>

<h3>ğŸŒ¾ ScÃ©nario : Effet des engrais sur le rendement du blÃ© Ã  SÃ©tif</h3>

<p>Un agronome des hauts plateaux de SÃ©tif teste trois traitements fertilisants sur le blÃ© dur : <strong>TÃ©moin</strong> (sans engrais), <strong>NPK</strong> (minÃ©ral) et <strong>Compost</strong> (organique). Six parcelles sont assignÃ©es alÃ©atoirement Ã  chaque traitement (n = 6 par groupe, N = 18 au total). Rendement (tonnes/hectare) :</p>

<table>
  <thead>
    <tr><th>TÃ©moin</th><th>NPK</th><th>Compost</th></tr>
  </thead>
  <tbody>
    <tr><td>2,1</td><td>3,5</td><td>3,0</td></tr>
    <tr><td>2,4</td><td>3,8</td><td>2,8</td></tr>
    <tr><td>1,9</td><td>3,2</td><td>3,3</td></tr>
    <tr><td>2,3</td><td>4,0</td><td>3,1</td></tr>
    <tr><td>2,0</td><td>3,6</td><td>2,9</td></tr>
    <tr><td>2,5</td><td>3,7</td><td>3,5</td></tr>
  </tbody>
</table>

<p><strong>Ã‰tape 1 :</strong> Moyennes des groupes : XÌ„<sub>TÃ©moin</sub> = 2,200, XÌ„<sub>NPK</sub> = 3,633, XÌ„<sub>Compost</sub> = 3,100, Moyenne gÃ©nÃ©rale = 2,978</p>

<p><strong>Ã‰tape 2 :</strong> SS<sub>Inter</sub> = <strong>6,307</strong> ; SS<sub>Intra</sub> = <strong>0,847</strong> ; SS<sub>Total</sub> = <strong>7,153</strong></p>

<p><strong>Ã‰tape 3 :</strong> CM<sub>Inter</sub> = 6,307 / 2 = <strong>3,153</strong> ; CM<sub>Intra</sub> = 0,847 / 15 = <strong>0,056</strong></p>

<p><strong>Ã‰tape 4 :</strong></p>
<p style="text-align:center; font-size:1.15em;"><strong>F(2, 15) = 3,153 / 0,056 = 55,89</strong></p>

<p><strong>Ã‰tape 5 :</strong> F<sub>critique</sub> Ã  Î± = 0,05 pour ddl (2, 15) = 3,68. Comme 55,89 â‰« 3,68, on rejette Hâ‚€. <em>p</em> &lt; 0,001.</p>

<p><strong>Ã‰tape 6 :</strong> Taille d'effet â€” Î·Â² = 6,307 / 7,153 = <strong>0,882</strong>. Soit 88,2 % de la variance totale est expliquÃ©e par le traitement fertilisant. C'est un trÃ¨s grand effet (Cohen, 1988).</p>

<hr>

<h2>ğŸ¯ Tests post-hoc : OÃ¹ est la diffÃ©rence ?</h2>

<p>Une ANOVA significative indique qu'<em>au moins un</em> groupe diffÃ¨re â€” mais pas <em>lequel</em>. Les tests post-hoc effectuent toutes les comparaisons par paires en contrÃ´lant le taux d'erreur de Type I global (Lee &amp; Lee, 2018).</p>

<h3>Test HSD de Tukey</h3>

<p>DÃ©veloppÃ© par <strong>John W. Tukey</strong> en 1953 dans son manuscrit Â« The Problem of Multiple Comparisons Â» Ã  l'UniversitÃ© de Princeton, le HSD utilise la <strong>distribution de l'Ã©tendue studentisÃ©e</strong> pour tester simultanÃ©ment toutes les diffÃ©rences par paires (Tukey, 1953). C'est la mÃ©thode la plus recommandÃ©e lorsque toutes les comparaisons par paires sont d'intÃ©rÃªt et que les tailles de groupes sont Ã©gales.</p>

<p>Pour notre exemple : HSD = 3,67 Ã— âˆš(0,056 / 6) = <strong>0,355</strong>. Toutes les comparaisons par paires dÃ©passent ce seuil â€” les trois traitements diffÃ¨rent significativement entre eux.</p>

<h3>Autres mÃ©thodes post-hoc majeures</h3>

<table>
  <thead>
    <tr><th>MÃ©thode</th><th>Meilleur usage</th><th>CaractÃ©ristiques</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>Bonferroni</strong></td><td>Peu de comparaisons planifiÃ©es</td><td>Divise Î± par le nombre de comparaisons. Simple mais conservateur.</td></tr>
    <tr><td><strong>ScheffÃ©</strong></td><td>Contrastes complexes</td><td>Le plus conservateur pour les paires, mais contrÃ´le l'erreur pour <em>tous</em> les contrastes possibles (ScheffÃ©, 1959).</td></tr>
    <tr><td><strong>Tukey-Kramer</strong></td><td>Toutes les paires, n inÃ©gaux</td><td>Extension de Tukey HSD pour designs dÃ©sÃ©quilibrÃ©s (Kramer, 1956).</td></tr>
    <tr><td><strong>Games-Howell</strong></td><td>Variances inÃ©gales</td><td>N'assume pas l'Ã©galitÃ© des variances ; s'associe Ã  l'ANOVA de Welch.</td></tr>
    <tr><td><strong>Dunnett</strong></td><td>Traitements vs. un tÃ©moin</td><td>Plus puissant que Tukey quand seules les comparaisons avec un contrÃ´le sont nÃ©cessaires.</td></tr>
  </tbody>
</table>

<hr>

<h2>ğŸ§® ANOVA Ã  deux facteurs : Quand deux facteurs agissent simultanÃ©ment</h2>

<p>Les expÃ©riences rÃ©elles impliquent souvent plus d'un facteur. Fisher lui-mÃªme l'a reconnu en Ã©tudiant comment <em>Ã  la fois</em> les variÃ©tÃ©s de pommes de terre <em>et</em> les traitements de fumure affectaient le rendement (Fisher &amp; Mackenzie, 1923). L'<strong>ANOVA Ã  deux facteurs</strong> (ou ANOVA factorielle) teste simultanÃ©ment les effets de deux variables indÃ©pendantes et, surtout, leur <strong>interaction</strong>.</p>

<p style="text-align:center; font-size:1.05em;"><strong>SS<sub>Total</sub> = SS<sub>A</sub> + SS<sub>B</sub> + SS<sub>AÃ—B</sub> + SS<sub>Erreur</sub></strong></p>

<p>L'<strong>interaction</strong> signifie que l'effet d'un facteur <em>dÃ©pend</em> du niveau de l'autre. Par exemple : le NPK pourrait augmenter considÃ©rablement le rendement de la VariÃ©tÃ© A mais avoir un effet minimal sur la VariÃ©tÃ© B. Sans ANOVA factorielle, ce pattern crucial serait invisible (Maxwell &amp; Delaney, 2004).</p>

<blockquote>ğŸ’¡ <strong>L'argument d'efficacitÃ© de Fisher :</strong> Avant Fisher, les chercheurs testaient une variable Ã  la fois â€” nÃ©cessitant des expÃ©riences sÃ©parÃ©es pour chaque facteur. Fisher montra que les plans factoriels sont non seulement plus informatifs (ils rÃ©vÃ¨lent les interactions) mais aussi plus <em>efficaces</em> car chaque observation contribue des informations sur chaque facteur simultanÃ©ment (Fisher, 1935).</blockquote>

<hr>

<h2>ğŸ” ANOVA Ã  mesures rÃ©pÃ©tÃ©es</h2>

<p>Lorsque les <em>mÃªmes sujets</em> sont mesurÃ©s Ã  plusieurs reprises, les observations sont corrÃ©lÃ©es. L'ANOVA standard assume l'indÃ©pendance. L'<strong>ANOVA Ã  mesures rÃ©pÃ©tÃ©es</strong> tient compte de la corrÃ©lation intra-sujet en partitionnant la variabilitÃ© due aux sujets :</p>

<p style="text-align:center; font-size:1.05em;"><strong>SS<sub>Total</sub> = SS<sub>Traitement</sub> + SS<sub>Sujets</sub> + SS<sub>Erreur</sub></strong></p>

<p>Elle introduit une hypothÃ¨se supplÃ©mentaire : la <strong>sphÃ©ricitÃ©</strong> â€” l'exigence que les variances de <em>toutes les diffÃ©rences par paires</em> soient Ã©gales. Lorsqu'elle est violÃ©e, deux corrections sont disponibles : <strong>Greenhouse-Geisser</strong> (1959), recommandÃ©e quand Îµ &lt; 0,75 ; et <strong>Huynh-Feldt</strong> (1976), moins conservatrice, recommandÃ©e quand Îµ â‰¥ 0,75.</p>

<hr>

<h2>ğŸ”§ HypothÃ¨ses et diagnostics</h2>

<table>
  <thead>
    <tr><th>HypothÃ¨se</th><th>Signification</th><th>Test</th><th>ConsÃ©quence de la violation</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>1. IndÃ©pendance</strong></td><td>Les observations sont indÃ©pendantes</td><td>Plan d'Ã©tude</td><td>La plus critique. Utiliser mesures rÃ©pÃ©tÃ©es ou modÃ¨les mixtes si violation.</td></tr>
    <tr><td><strong>2. NormalitÃ©</strong></td><td>Les rÃ©sidus suivent une loi normale</td><td>Shapiro-Wilk ; graphiques Q-Q</td><td>L'ANOVA est <em>robuste</em> aux violations de normalitÃ© quand n â‰¥ 15 par groupe (Glass et al., 1972). Sinon, utiliser Kruskal-Wallis.</td></tr>
    <tr><td><strong>3. HomoscÃ©dasticitÃ©</strong></td><td>Variances Ã©gales entre les groupes</td><td>Test de Levene (1960) ; Brown-Forsythe (1974)</td><td>Si violÃ©e, utiliser l'<strong>ANOVA de Welch</strong> (1951). Critique surtout quand les tailles de groupes sont inÃ©gales.</td></tr>
  </tbody>
</table>

<blockquote>ğŸ§  <strong>L'insight de robustesse :</strong> Glass, Peckham et Sanders (1972) ont montrÃ© que l'ANOVA est remarquablement robuste aux violations de normalitÃ©. La violation la plus dangereuse est l'<em>hÃ©tÃ©roscÃ©dasticitÃ© combinÃ©e Ã  des tailles d'Ã©chantillons inÃ©gales</em>. Dans ce cas, l'ANOVA de Welch est fortement recommandÃ©e.</blockquote>

<hr>

<h2>âš¡ ANOVA de Welch : L'alternative robuste moderne</h2>

<p>En 1951, <strong>Bernard Lewis Welch</strong> publia dans <em>Biometrika</em> une extension de son test t Ã  plusieurs groupes (Welch, 1951). L'ANOVA de Welch utilise des moyennes pondÃ©rÃ©es et des degrÃ©s de libertÃ© ajustÃ©s pour produire des tests F valides mÃªme avec des variances inÃ©gales. Beaucoup de statisticiens modernes la recommandent comme <em>choix par dÃ©faut</em> (Delacre et al., 2019).</p>

<hr>

<h2>ğŸ“ Tailles d'effet</h2>

<table>
  <thead>
    <tr><th>Mesure</th><th>Formule</th><th>InterprÃ©tation</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>Î·Â²</strong></td><td>SS<sub>Effet</sub> / SS<sub>Total</sub></td><td>Proportion de variance totale expliquÃ©e. BiaisÃ© positivement. Seuils : 0,01 = petit, 0,06 = moyen, 0,14 = grand (Cohen, 1988).</td></tr>
    <tr><td><strong>Î·Â² partiel</strong></td><td>SS<sub>Effet</sub> / (SS<sub>Effet</sub> + SS<sub>Erreur</sub>)</td><td>Standard dans les plans factoriels. C'est ce que SPSS rapporte par dÃ©faut (Richardson, 2011).</td></tr>
    <tr><td><strong>Ï‰Â²</strong></td><td>(SS<sub>B</sub> âˆ’ (kâˆ’1)CM<sub>W</sub>) / (SS<sub>T</sub> + CM<sub>W</sub>)</td><td>Estimateur moins biaisÃ© que Î·Â². RecommandÃ© pour l'infÃ©rence populationnelle (Lakens, 2013).</td></tr>
    <tr><td><strong><em>f</em> de Cohen</strong></td><td>âˆš(Î·Â² / (1 âˆ’ Î·Â²))</td><td>Pour l'analyse de puissance. Seuils : 0,10 = petit, 0,25 = moyen, 0,40 = grand (Cohen, 1988).</td></tr>
  </tbody>
</table>

<hr>

<h2>ğŸ“ Directives de rÃ©daction APA</h2>

<p>L'APA (2020) exige de rapporter le F, les degrÃ©s de libertÃ©, la valeur <em>p</em> exacte et une mesure de taille d'effet :</p>

<p><em>Â« Une ANOVA Ã  un facteur a rÃ©vÃ©lÃ© une diffÃ©rence statistiquement significative du rendement en blÃ© entre les trois traitements fertilisants, F(2, 15) = 55,89, p &lt; ,001, Î·Â² = ,88. Les comparaisons post-hoc de Tukey HSD ont montrÃ© que le NPK (M = 3,63, Ã‰T = 0,28) a produit un rendement significativement supÃ©rieur au Compost (M = 3,10, Ã‰T = 0,24, p &lt; ,01) et au TÃ©moin (M = 2,20, Ã‰T = 0,23, p &lt; ,001). Â»</em></p>

<hr>

<h2>ğŸ—ºï¸ La famille complÃ¨te de l'ANOVA</h2>

<table>
  <thead>
    <tr><th>Plan</th><th>Type d'ANOVA</th><th>Quand utiliser</th></tr>
  </thead>
  <tbody>
    <tr><td>Un facteur, groupes indÃ©pendants</td><td><strong>ANOVA Ã  un facteur</strong></td><td>Comparer 3+ groupes</td></tr>
    <tr><td>Deux facteurs, groupes indÃ©pendants</td><td><strong>ANOVA factorielle (Ã  deux facteurs)</strong></td><td>Deux facteurs croisÃ©s. Teste effets principaux + interaction.</td></tr>
    <tr><td>Un facteur, mÃªmes sujets</td><td><strong>ANOVA Ã  mesures rÃ©pÃ©tÃ©es</strong></td><td>MÃªmes sujets mesurÃ©s Ã  3+ moments ou conditions.</td></tr>
    <tr><td>Deux facteurs : un inter, un intra</td><td><strong>ANOVA mixte (split-plot)</strong></td><td>Groupes diffÃ©rents sur un facteur, mesures rÃ©pÃ©tÃ©es sur l'autre.</td></tr>
    <tr><td>Un facteur, avec covariable continue</td><td><strong>ANCOVA</strong></td><td>ContrÃ´le une variable confondante. Augmente la puissance.</td></tr>
    <tr><td>Plusieurs variables dÃ©pendantes</td><td><strong>MANOVA</strong></td><td>Teste les diffÃ©rences sur plusieurs rÃ©sultats simultanÃ©ment.</td></tr>
    <tr><td>Variances inÃ©gales</td><td><strong>ANOVA de Welch</strong></td><td>Alternative robuste (Welch, 1951).</td></tr>
    <tr><td>DonnÃ©es non normales / ordinales</td><td><strong>Test H de Kruskal-Wallis</strong></td><td>Alternative non paramÃ©trique (Kruskal &amp; Wallis, 1952).</td></tr>
  </tbody>
</table>

<hr>

<h2>âš ï¸ Erreurs courantes Ã  Ã©viter</h2>

<p><strong>1.</strong> Effectuer des tests t multiples au lieu d'une ANOVA â€” cela gonfle l'erreur de Type I.</p>
<p><strong>2.</strong> Ignorer l'interaction dans les plans factoriels â€” si l'interaction est significative, les effets principaux seuls sont trompeurs (Maxwell &amp; Delaney, 2004).</p>
<p><strong>3.</strong> Ne rapporter que les valeurs <em>p</em> sans tailles d'effet â€” toujours inclure Î·Â², Î·Â² partiel ou Ï‰Â² (Lakens, 2013).</p>
<p><strong>4.</strong> Utiliser l'ANOVA classique quand les variances sont inÃ©gales â€” passer Ã  l'ANOVA de Welch avec Games-Howell (Delacre et al., 2019).</p>
<p><strong>5.</strong> Oublier de vÃ©rifier les hypothÃ¨ses â€” toujours tester normalitÃ© (Shapiro-Wilk) et homoscÃ©dasticitÃ© (Levene).</p>
<p><strong>6.</strong> Faire des tests post-hoc aprÃ¨s une ANOVA non significative â€” les tests post-hoc ne sont justifiÃ©s que si le test omnibus est significatif.</p>

<hr>

<h2>ğŸ§© SynthÃ¨se : L'architecture de la preuve expÃ©rimentale</h2>

<p>L'Analyse de la Variance de Fisher est, en son cÅ“ur, un cadre de pensÃ©e sur la preuve. Elle demande : de toute la variabilitÃ© observÃ©e dans une expÃ©rience, quelle part est attribuable Ã  notre manipulation dÃ©libÃ©rÃ©e (le traitement), et quelle part n'est que du bruit ? Quand le signal domine le bruit â€” quand le rapport F est grand â€” nous avons la preuve que le traitement a un effet.</p>

<p>De ses origines dans les champs de blÃ© de Rothamsted Ã  son application ubiquitaire en mÃ©decine, psychologie, agriculture, Ã©cologie et ingÃ©nierie, l'ANOVA reste la mÃ©thode statistique la plus utilisÃ©e pour comparer des moyennes de groupes. Comme Fisher l'a Ã©crit : Â« Consulter le statisticien aprÃ¨s la fin d'une expÃ©rience, c'est souvent lui demander de procÃ©der Ã  un examen post-mortem. Il peut peut-Ãªtre dire de quoi l'expÃ©rience est morte. Â» La leÃ§on est claire â€” l'ANOVA n'est pas un simple calcul ; c'est une faÃ§on de penser les expÃ©riences.</p>

<hr>

<h2>ğŸ“š RÃ©fÃ©rences</h2>

<p>American Psychological Association. (2020). <em>Publication manual of the American Psychological Association</em> (7th ed.). Author. https://doi.org/10.1037/0000165-000</p>

<p>Brown, M. B., &amp; Forsythe, A. B. (1974). Robust tests for the equality of variances. <em>Journal of the American Statistical Association</em>, <em>69</em>(346), 364â€“367. https://doi.org/10.1080/01621459.1974.10482955</p>

<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Lawrence Erlbaum Associates.</p>

<p>Delacre, M., Leys, C., Mora, Y. L., &amp; Lakens, D. (2019). Taking parametric assumptions seriously: Arguments for the use of Welch's F-test instead of the classical F-test in one-way ANOVA. <em>International Review of Social Psychology</em>, <em>32</em>(1), 13. https://doi.org/10.5334/irsp.198</p>

<p>Fisher, R. A. (1925). <em>Statistical methods for research workers</em>. Oliver and Boyd.</p>

<p>Fisher, R. A. (1935). <em>The design of experiments</em>. Oliver and Boyd.</p>

<p>Fisher, R. A., &amp; Mackenzie, W. A. (1923). Studies in crop variation. II. The manurial response of different potato varieties. <em>Journal of Agricultural Science</em>, <em>13</em>(3), 311â€“320. https://doi.org/10.1017/S0021859600003592</p>

<p>Glass, G. V., Peckham, P. D., &amp; Sanders, J. R. (1972). Consequences of failure to meet assumptions underlying the fixed effects analyses of variance and covariance. <em>Review of Educational Research</em>, <em>42</em>(3), 237â€“288. https://doi.org/10.3102/00346543042003237</p>

<p>Greenhouse, S. W., &amp; Geisser, S. (1959). On methods in the analysis of profile data. <em>Psychometrika</em>, <em>24</em>(2), 95â€“112. https://doi.org/10.1007/BF02289823</p>

<p>Huynh, H., &amp; Feldt, L. S. (1976). Estimation of the Box correction for degrees of freedom from sample data in randomized block and split-plot designs. <em>Journal of Educational Statistics</em>, <em>1</em>(1), 69â€“82. https://doi.org/10.3102/10769986001001069</p>

<p>Keppel, G., &amp; Wickens, T. D. (2004). <em>Design and analysis: A researcher's handbook</em> (4th ed.). Pearson Prentice Hall.</p>

<p>Kruskal, W. H., &amp; Wallis, W. A. (1952). Use of ranks in one-criterion variance analysis. <em>Journal of the American Statistical Association</em>, <em>47</em>(260), 583â€“621. https://doi.org/10.1080/01621459.1952.10483441</p>

<p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science. <em>Frontiers in Psychology</em>, <em>4</em>, 863. https://doi.org/10.3389/fpsyg.2013.00863</p>

<p>LangkjÃ¦r-Bain, R. (2018). Where the seeds of modern statistics were sown. <em>Significance</em>, <em>15</em>(4), 16â€“21. https://doi.org/10.1111/j.1740-9713.2018.01144.x</p>

<p>Lee, S., &amp; Lee, D. K. (2018). What is the proper way to apply the multiple comparison test? <em>Korean Journal of Anesthesiology</em>, <em>71</em>(5), 353â€“360. https://doi.org/10.4097/kja.d.18.00242</p>

<p>Levene, H. (1960). Robust tests for equality of variances. In I. Olkin (Ed.), <em>Contributions to probability and statistics</em> (pp. 278â€“292). Stanford University Press.</p>

<p>Maxwell, S. E., &amp; Delaney, H. D. (2004). <em>Designing experiments and analyzing data</em> (2nd ed.). Lawrence Erlbaum Associates.</p>

<p>Richardson, J. T. E. (2011). Eta squared and partial eta squared as measures of effect size in educational research. <em>Educational Research Review</em>, <em>6</em>(2), 135â€“147. https://doi.org/10.1016/j.edurev.2010.12.001</p>

<p>Russell, E. J. (1966). <em>A history of agricultural science in Great Britain, 1620â€“1954</em>. Allen and Unwin.</p>

<p>ScheffÃ©, H. (1959). <em>The analysis of variance</em>. Wiley.</p>

<p>Tukey, J. W. (1953). <em>The problem of multiple comparisons</em>. Unpublished manuscript, Princeton University.</p>

<p>Welch, B. L. (1951). On the comparison of several mean values: An alternative approach. <em>Biometrika</em>, <em>38</em>(3/4), 330â€“336. https://doi.org/10.1093/biomet/38.3-4.330</p>
