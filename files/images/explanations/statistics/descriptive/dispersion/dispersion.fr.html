<h2>â†”ï¸ La Dispersion : Mesurer l'Ã‰tendue de vos DonnÃ©es</h2>

<p>Deux classes d'Ã©tudiants passent le mÃªme examen. Les deux obtiennent une moyenne de 75 sur 100. Le doyen regarde les rÃ©sultats et dÃ©clare : <em>Â« Les deux classes ont obtenu des rÃ©sultats Ã©quivalents. Â»</em> Mais est-ce vrai ? Dans la classe A, chaque Ã©tudiant a obtenu entre 70 et 80 â€” un regroupement serrÃ© et rassurant. Dans la classe B, les notes vont de 20 Ã  100 â€” des montagnes russes. Les <strong>moyennes sont identiques</strong>, mais les <em>histoires</em> sont complÃ¨tement diffÃ©rentes. C'est prÃ©cisÃ©ment pourquoi nous avons besoin des <strong>mesures de dispersion</strong>.</p>

<p>La dispersion â€” Ã©galement appelÃ©e variabilitÃ©, Ã©talement ou Ã©parpillement â€” quantifie le degrÃ© auquel les valeurs des donnÃ©es diffÃ¨rent les unes des autres et du centre. Si la tendance centrale vous dit <em>oÃ¹</em> se trouvent les donnÃ©es, la dispersion vous dit <em>Ã  quel point vous pouvez faire confiance Ã  ce centre</em>. Comme l'ont soulignÃ© Freedman et al. (2007), rapporter une moyenne sans mesure de dispersion, c'est comme indiquer une destination sans mentionner l'Ã©tat de la route. Weisberg (1992) a dÃ©fendu l'idÃ©e que tendance centrale et variabilitÃ© sont des partenaires insÃ©parables : l'une n'a pas de sens sans l'autre.</p>

<blockquote>ğŸ’¡ <strong>L'IdÃ©e Centrale :</strong> Deux ensembles de donnÃ©es peuvent avoir la mÃªme moyenne, la mÃªme mÃ©diane et le mÃªme mode â€” et pourtant Ãªtre fondamentalement diffÃ©rents. Les mesures de dispersion capturent ce que la tendance centrale manque : <strong>le degrÃ© d'incertitude, de risque et de variabilitÃ©</strong> cachÃ© dans les donnÃ©es. De l'agriculture Ã  la finance, comprendre l'Ã©talement est souvent plus important que de connaÃ®tre la moyenne.</blockquote>

<hr>

<h2>ğŸ“Š Pourquoi la Dispersion est Importante</h2>

<p>Les mesures de dispersion remplissent des fonctions essentielles dans toute discipline utilisant des donnÃ©es (Moore et al., 2021 ; Agresti & Finlay, 2018) :</p>

<table>
  <thead>
    <tr><th>Fonction</th><th>Description</th><th>Exemple</th></tr>
  </thead>
  <tbody>
    <tr><td>ğŸ¯ <strong>Ã‰valuation de la prÃ©cision</strong></td><td>Ã‰valuer Ã  quel point les mesures se regroupent autour du centre</td><td>Instruments de laboratoire avec Ïƒ = 0,01 mm vs Ïƒ = 2 mm</td></tr>
    <tr><td>âš–ï¸ <strong>Comparaison de groupes</strong></td><td>DÃ©terminer si deux groupes diffÃ¨rent rÃ©ellement ou se chevauchent</td><td>EfficacitÃ© du mÃ©dicament A vs B â€” mÃªme moyenne mais Ã©talement diffÃ©rent</td></tr>
    <tr><td>ğŸ”” <strong>NormalitÃ© et forme</strong></td><td>L'Ã©cart-type dÃ©finit la largeur des courbes en cloche et des intervalles de confiance</td><td>La rÃ¨gle 68-95-99,7% nÃ©cessite de connaÃ®tre Ïƒ</td></tr>
    <tr><td>ğŸ§ª <strong>ContrÃ´le qualitÃ©</strong></td><td>Surveiller la rÃ©gularitÃ© des processus en fabrication et agriculture</td><td>Variation acceptable du poids des semences par lot</td></tr>
    <tr><td>ğŸ“ˆ <strong>Risque et dÃ©cision</strong></td><td>Plus de variabilitÃ© = plus d'incertitude = plus de risque</td><td>Les investisseurs prÃ©fÃ¨rent des portefeuilles Ã  CV plus faible pour le mÃªme rendement</td></tr>
    <tr><td>ğŸ§± <strong>Fondement de l'infÃ©rence</strong></td><td>La variance est le moteur de tout test infÃ©rentiel : t-tests, ANOVA, rÃ©gression, intervalles de confiance</td><td>Erreur standard = Ïƒ/âˆšn â€” le pont entre statistique descriptive et infÃ©rentielle</td></tr>
  </tbody>
</table>

<blockquote>ğŸ§ª <strong>Perspective Agronomique :</strong> Un agronome testant un nouveau cultivar de blÃ© sur les hauts plateaux algÃ©riens a besoin de plus que la moyenne du rendement. Si le cultivar a une moyenne de 35 q/ha mais varie de 15 Ã  55 entre les parcelles, ce cultivar est <em>risquÃ©</em>. Un second cultivar avec une moyenne de 32 q/ha mais variant de 28 Ã  36 est bien plus <strong>fiable</strong> â€” et la fiabilitÃ© compte souvent plus que les moyennes brutes en contexte de sÃ©curitÃ© alimentaire (Gomez & Gomez, 1984).</blockquote>

<hr>

<h2>ğŸ“ Taxonomie des Mesures de Dispersion</h2>

<p>Avant d'examiner chaque mesure, voyons la vue d'ensemble. Les mesures de dispersion se divisent en deux grandes familles (Wackerly et al., 2014) :</p>

<table>
  <thead>
    <tr><th>Type</th><th>Mesures</th><th>UnitÃ©s originales ?</th><th>Comparable entre jeux de donnÃ©es diffÃ©rents ?</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>Mesures absolues</strong></td><td>Ã‰tendue, EIQ, Ã‰cart moyen, Variance, Ã‰cart-type</td><td>âœ… (sauf la variance qui met au carrÃ©)</td><td>âŒ Uniquement si mÃªmes unitÃ©s et moyennes similaires</td></tr>
    <tr><td><strong>Mesures relatives</strong></td><td>Coefficient de Variation (CV)</td><td>âŒ Sans dimension (en %)</td><td>âœ… Peut comparer entre unitÃ©s et Ã©chelles diffÃ©rentes</td></tr>
  </tbody>
</table>

<hr>

<h2>1ï¸âƒ£ L'Ã‰tendue (R) â€” L'AperÃ§u le Plus Simple</h2>

<h3>DÃ©finition et Calcul</h3>

<p>L'<strong>Ã©tendue</strong> est la diffÃ©rence entre la valeur maximale et la valeur minimale d'un jeu de donnÃ©es. C'est la mesure de dispersion la plus rapide et la plus intuitive â€” une simple soustraction qui indique l'envergure totale de vos donnÃ©es (Triola, 2018) :</p>

<p style="text-align:center;"><strong>R = X<sub>max</sub> âˆ’ X<sub>min</sub></strong></p>

<p><strong>Exemple :</strong> Cinq parcelles de blÃ© produisent 28, 31, 35, 29 et 32 q/ha.</p>
<p style="text-align:center;"><strong>R = 35 âˆ’ 28 = 7 q/ha</strong></p>

<h3>PropriÃ©tÃ©s de l'Ã‰tendue</h3>

<table>
  <thead>
    <tr><th>PropriÃ©tÃ©</th><th>Ã‰valuation</th></tr>
  </thead>
  <tbody>
    <tr><td>âœ… SimplicitÃ©</td><td>Triviale Ã  calculer â€” ne nÃ©cessite que les valeurs extrÃªmes</td></tr>
    <tr><td>âœ… Intuitive</td><td>Tout le monde comprend Â« les donnÃ©es vont de X Ã  Y Â»</td></tr>
    <tr><td>âŒ Sensible aux valeurs aberrantes</td><td>Une seule valeur extrÃªme peut gonfler Ã©normÃ©ment l'Ã©tendue</td></tr>
    <tr><td>âŒ Ignore les donnÃ©es intÃ©rieures</td><td>N'utilise que 2 des n observations â€” ne dit rien sur la rÃ©partition du reste</td></tr>
    <tr><td>âŒ CroÃ®t avec la taille de l'Ã©chantillon</td><td>Les Ã©chantillons plus grands capturent plus facilement les extrÃªmes</td></tr>
  </tbody>
</table>

<hr>

<h2>2ï¸âƒ£ Ã‰cart Interquartile (EIQ) â€” Le Milieu Robuste</h2>

<h3>DÃ©finition</h3>

<p>L'<strong>Ã©cart interquartile</strong> mesure la dispersion des 50% centraux des donnÃ©es. Il est dÃ©fini comme la diffÃ©rence entre le troisiÃ¨me quartile (Qâ‚ƒ) et le premier quartile (Qâ‚) :</p>

<p style="text-align:center;"><strong>EIQ = Qâ‚ƒ âˆ’ Qâ‚</strong></p>

<p>L'EIQ est le partenaire naturel de la <strong>mÃ©diane</strong> â€” tout comme l'Ã©cart-type accompagne la moyenne. Parce qu'il Ã©carte les 25% infÃ©rieurs et supÃ©rieurs, il est <strong>rÃ©sistant aux valeurs aberrantes</strong>, ce qui en fait la mesure de dispersion prÃ©fÃ©rÃ©e pour les distributions asymÃ©triques (Moore et al., 2021).</p>

<blockquote>ğŸ“¦ <strong>Lien avec le Diagramme en BoÃ®te :</strong> L'EIQ est exactement ce que la Â« boÃ®te Â» reprÃ©sente dans un diagramme en boÃ®te Ã  moustaches. La boÃ®te capture les 50% centraux des observations, et sa largeur (l'EIQ) donne un sentiment visuel immÃ©diat de la dispersion. Les valeurs aberrantes sont signalÃ©es comme des points au-delÃ  de 1,5 Ã— EIQ â€” une rÃ¨gle proposÃ©e par John Tukey (1977).</blockquote>

<hr>

<h2>3ï¸âƒ£ Ã‰cart Moyen Absolu (EMA) â€” L'Alternative Intuitive</h2>

<p>L'<strong>Ã©cart moyen absolu</strong> est la moyenne des diffÃ©rences absolues entre chaque valeur et la moyenne. Il rÃ©pond Ã  une question magnifiquement simple : <em>Â« En moyenne, Ã  quelle distance les donnÃ©es se trouvent-elles du centre ? Â»</em></p>

<p style="text-align:center;"><strong>EMA = (1/n) Ã— Î£|xáµ¢ âˆ’ xÌ„|</strong></p>

<p>L'EMA est sans doute plus intuitif que la variance car il ne met rien au carrÃ©. Pourtant, il est tombÃ© en disgrÃ¢ce car les <strong>valeurs absolues sont mathÃ©matiquement difficiles</strong> Ã  manipuler â€” impossibles Ã  dÃ©river proprement et sans les propriÃ©tÃ©s algÃ©briques des carrÃ©s. C'est pourquoi Pearson, Fisher et les architectes de la statistique moderne ont privilÃ©giÃ© la variance (Gorard, 2005).</p>

<hr>

<h2>4ï¸âƒ£ Variance (ÏƒÂ² ou sÂ²) â€” Le Cheval de Bataille de la Statistique</h2>

<h3>Pourquoi Ã‰lever au CarrÃ© ?</h3>

<p>Si nous faisions simplement la moyenne des Ã©carts Ã  la moyenne sans valeur absolue, les Ã©carts positifs et nÃ©gatifs s'annuleraient, donnant toujours zÃ©ro (rappel : Î£(xáµ¢ âˆ’ xÌ„) = 0 est une propriÃ©tÃ© fondamentale de la moyenne). Deux options existent : prendre les valeurs absolues (â†’ EMA) ou <strong>mettre au carrÃ©</strong> (â†’ variance). Le monde statistique a choisi la mise au carrÃ©, pour des raisons profondes (Wackerly et al., 2014) :</p>

<table>
  <thead>
    <tr><th>Raison</th><th>Explication</th></tr>
  </thead>
  <tbody>
    <tr><td>ğŸ“ <strong>DÃ©rivabilitÃ©</strong></td><td>xÂ² est lisse et dÃ©rivable partout, tandis que |x| a un point anguleux en zÃ©ro â€” rendant possible l'optimisation par les moindres carrÃ©s</td></tr>
    <tr><td>ğŸ§® <strong>DÃ©composition algÃ©brique</strong></td><td>La variance se dÃ©compose : variance totale = variance inter-groupes + variance intra-groupes. C'est le fondement de l'ANOVA</td></tr>
    <tr><td>ğŸ”— <strong>AdditivitÃ©</strong></td><td>Pour des variables indÃ©pendantes, Var(X + Y) = Var(X) + Var(Y). Aucune telle propriÃ©tÃ© n'existe pour les Ã©carts absolus</td></tr>
    <tr><td>âš¡ <strong>Accentuation des extrÃªmes</strong></td><td>La mise au carrÃ© pÃ©nalise les grands Ã©carts de faÃ§on disproportionnÃ©e â€” un point Ã  3 unitÃ©s contribue 9, pas 3</td></tr>
    <tr><td>ğŸ”” <strong>Lien avec la loi normale</strong></td><td>La distribution normale est entiÃ¨rement dÃ©finie par deux paramÃ¨tres : la moyenne et la variance</td></tr>
  </tbody>
</table>

<h3>Variance de Population vs Variance d'Ã‰chantillon</h3>

<table>
  <thead>
    <tr><th>Contexte</th><th>Formule</th><th>Symbole</th><th>DÃ©nominateur</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>Variance de population</strong></td><td>ÏƒÂ² = Î£(xáµ¢ âˆ’ Î¼)Â² / N</td><td>ÏƒÂ²</td><td>N (taille de la population)</td></tr>
    <tr><td><strong>Variance d'Ã©chantillon</strong></td><td>sÂ² = Î£(xáµ¢ âˆ’ xÌ„)Â² / (n âˆ’ 1)</td><td>sÂ²</td><td>n âˆ’ 1 (correction de Bessel)</td></tr>
  </tbody>
</table>

<h3>ğŸ”‘ La Correction de Bessel : Pourquoi n âˆ’ 1 ?</h3>

<p>Lorsqu'on calcule la variance d'un Ã©chantillon, on divise par <strong>n âˆ’ 1</strong> au lieu de n. Cet ajustement, appelÃ© <strong>correction de Bessel</strong>, du nom de Friedrich Bessel qui appliqua des techniques similaires dans son analyse d'observations astronomiques en 1818 (Reichel, 2025).</p>

<p><strong>L'intuition :</strong> La moyenne Ã©chantillonnale xÌ„ est toujours positionnÃ©e au centre exact des donnÃ©es de l'Ã©chantillon (par dÃ©finition). Mais la moyenne de population Î¼ pourrait Ãªtre n'importe oÃ¹. Parce que xÌ„ est <em>garanti</em> d'Ãªtre plus proche des points de l'Ã©chantillon que Î¼ ne l'est habituellement, diviser par n <strong>sous-estime systÃ©matiquement</strong> la vraie variance de population. Le facteur n âˆ’ 1 compense ce biais descendant.</p>

<p><strong>InterprÃ©tation par les degrÃ©s de libertÃ© :</strong> Dans un Ã©chantillon de n observations, une fois la moyenne connue, seules n âˆ’ 1 valeurs sont Â« libres Â» de varier indÃ©pendamment. La derniÃ¨re est dÃ©terminÃ©e par les autres et la moyenne. Il n'y a donc que <strong>n âˆ’ 1 degrÃ©s de libertÃ©</strong> disponibles pour estimer la variance (Wackerly et al., 2014).</p>

<blockquote>ğŸ“ <strong>Le cas extrÃªme :</strong> Si n = 1, diviser par n donne variance = 0 pour toute population â€” clairement faux. Diviser par n âˆ’ 1 = 0 est indÃ©fini, signalant correctement qu'on ne peut pas estimer la variance Ã  partir d'une seule observation. La correction perd son importance quand n est grand (999 vs 1000), mais pour de petits Ã©chantillons biologiques (n = 5, 10, 20), elle est cruciale (Freedman et al., 2007).</blockquote>

<h3>Exemple DÃ©taillÃ© Pas Ã  Pas</h3>

<p>DonnÃ©es : Cinq mesures de pH du sol dans un champ Ã  SÃ©tif : {6,2 ; 6,8 ; 7,1 ; 6,5 ; 7,4}.</p>

<table>
  <thead>
    <tr><th>Ã‰tape</th><th>OpÃ©ration</th><th>RÃ©sultat</th></tr>
  </thead>
  <tbody>
    <tr><td>1</td><td>Calculer la moyenne : xÌ„ = (6,2 + 6,8 + 7,1 + 6,5 + 7,4) / 5</td><td>xÌ„ = 34,0 / 5 = <strong>6,80</strong></td></tr>
    <tr><td>2</td><td>Calculer les Ã©carts : (xáµ¢ âˆ’ xÌ„)</td><td>âˆ’0,6 ; 0,0 ; 0,3 ; âˆ’0,3 ; 0,6</td></tr>
    <tr><td>3</td><td>Mettre au carrÃ© : (xáµ¢ âˆ’ xÌ„)Â²</td><td>0,36 ; 0,00 ; 0,09 ; 0,09 ; 0,36</td></tr>
    <tr><td>4</td><td>Somme des carrÃ©s : Î£(xáµ¢ âˆ’ xÌ„)Â²</td><td><strong>0,90</strong></td></tr>
    <tr><td>5</td><td>Diviser par (n âˆ’ 1) = 4</td><td>sÂ² = 0,90 / 4 = <strong>0,225</strong></td></tr>
  </tbody>
</table>

<p>La variance est <strong>sÂ² = 0,225</strong>. Mais attention : elle est en <strong>unitÃ©s au carrÃ©</strong> (pHÂ²), ce qui n'est pas directement interprÃ©table. D'oÃ¹ la nÃ©cessitÃ© de l'Ã©cart-type.</p>

<hr>

<h2>5ï¸âƒ£ Ã‰cart-Type (Ïƒ ou s) â€” L'Ã‰talon-Or</h2>

<h3>DÃ©finition</h3>

<p>L'<strong>Ã©cart-type</strong> est simplement la <strong>racine carrÃ©e de la variance</strong>. Cette transformation rÃ©sout le problÃ¨me des unitÃ©s au carrÃ© et donne une mesure exprimÃ©e dans les <em>mÃªmes unitÃ©s que les donnÃ©es originales</em> (Moore et al., 2021) :</p>

<table>
  <thead>
    <tr><th>Contexte</th><th>Formule</th><th>Symbole</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>Population</strong></td><td>Ïƒ = âˆš[Î£(xáµ¢ âˆ’ Î¼)Â² / N]</td><td>Ïƒ (sigma)</td></tr>
    <tr><td><strong>Ã‰chantillon</strong></td><td>s = âˆš[Î£(xáµ¢ âˆ’ xÌ„)Â² / (n âˆ’ 1)]</td><td>s</td></tr>
  </tbody>
</table>

<p>De notre exemple : <strong>s = âˆš0,225 â‰ˆ 0,474 unitÃ©s pH</strong>. Les mesures de pH s'Ã©cartent typiquement de 0,47 unitÃ©s de la moyenne de 6,80.</p>

<h3>La RÃ¨gle Empirique (68â€“95â€“99,7)</h3>

<p>Pour des donnÃ©es approximativement <strong>normalement distribuÃ©es</strong>, l'Ã©cart-type a une interprÃ©tation remarquable (Triola, 2018) :</p>

<table>
  <thead>
    <tr><th>Intervalle</th><th>Contient environ</th><th>Signification</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>xÌ„ Â± 1s</strong></td><td>~68% des donnÃ©es</td><td>Environ deux tiers des observations tombent Ã  un Ã©cart-type de la moyenne</td></tr>
    <tr><td><strong>xÌ„ Â± 2s</strong></td><td>~95% des donnÃ©es</td><td>Presque toutes les observations Â« normales Â» tombent Ã  deux Ã©carts-types</td></tr>
    <tr><td><strong>xÌ„ Â± 3s</strong></td><td>~99,7% des donnÃ©es</td><td>Pratiquement toutes â€” au-delÃ  est extrÃªmement rare</td></tr>
  </tbody>
</table>

<h3>ThÃ©orÃ¨me de Tchebychev â€” Pour Toute Distribution</h3>

<p>Et si les donnÃ©es ne sont <em>pas</em> normales ? Pafnouti Tchebychev a prouvÃ© une borne universelle applicable Ã  <strong>toute distribution</strong> (Wackerly et al., 2014) :</p>

<p style="text-align:center;"><strong>Au moins (1 âˆ’ 1/kÂ²) Ã— 100% des donnÃ©es se trouvent dans k Ã©carts-types de la moyenne</strong></p>

<table>
  <thead>
    <tr><th>k</th><th>Minimum % dans xÌ„ Â± ks</th></tr>
  </thead>
  <tbody>
    <tr><td>2</td><td>Au moins 75%</td></tr>
    <tr><td>3</td><td>Au moins 88,9%</td></tr>
    <tr><td>4</td><td>Au moins 93,75%</td></tr>
  </tbody>
</table>

<h3>PropriÃ©tÃ©s ClÃ©s de l'Ã‰cart-Type</h3>

<table>
  <thead>
    <tr><th>#</th><th>PropriÃ©tÃ©</th><th>Ã‰noncÃ©</th><th>Importance</th></tr>
  </thead>
  <tbody>
    <tr><td>1</td><td>âœ… <strong>Non-nÃ©gatif</strong></td><td>s â‰¥ 0, et s = 0 seulement quand toutes les valeurs sont identiques</td><td>Dispersion nulle = aucune variabilitÃ©</td></tr>
    <tr><td>2</td><td>ğŸ“ <strong>MÃªmes unitÃ©s</strong></td><td>Si les donnÃ©es sont en kg, s est en kg</td><td>Directement interprÃ©table, contrairement Ã  la variance</td></tr>
    <tr><td>3</td><td>ğŸ”— <strong>Transformation linÃ©aire</strong></td><td>Si y = a + bx, alors s<sub>y</sub> = |b| Ã— s<sub>x</sub></td><td>Ajouter une constante ne change pas la dispersion ; multiplier l'ajuste proportionnellement</td></tr>
    <tr><td>4</td><td>âš¡ <strong>Sensible aux valeurs extrÃªmes</strong></td><td>La mise au carrÃ© amplifie les grands Ã©carts</td><td>Un avantage pour la dÃ©tection, un inconvÃ©nient pour la robustesse</td></tr>
    <tr><td>5</td><td>ğŸ“ˆ <strong>Fondement de l'infÃ©rence</strong></td><td>ES = s/âˆšn ; IC = xÌ„ Â± z Ã— ES</td><td>Erreur standard, intervalles de confiance et tests d'hypothÃ¨ses dÃ©pendent tous de s</td></tr>
  </tbody>
</table>

<hr>

<h2>6ï¸âƒ£ Coefficient de Variation (CV) â€” La Mesure Relative</h2>

<h3>Le ProblÃ¨me RÃ©solu par le CV</h3>

<p>Imaginez que vous mesurez la hauteur de tournesols (moyenne = 180 cm, s = 12 cm) et la longueur de leurs graines (moyenne = 1,2 cm, s = 0,3 cm). Quelle variable est Â« plus variable Â» ? Vous <strong>ne pouvez pas</strong> rÃ©pondre en comparant les Ã©carts-types â€” ils utilisent des unitÃ©s et des Ã©chelles diffÃ©rentes. C'est lÃ  qu'intervient le <strong>coefficient de variation</strong> (Pearson, 1896).</p>

<h3>DÃ©finition</h3>

<p>Le <strong>coefficient de variation</strong>, introduit par Karl Pearson en 1896, exprime l'Ã©cart-type en pourcentage de la moyenne. C'est une mesure <strong>adimensionnelle</strong> permettant de comparer la variabilitÃ© entre jeux de donnÃ©es complÃ¨tement diffÃ©rents :</p>

<p style="text-align:center;"><strong>CV = (s / xÌ„) Ã— 100%</strong></p>

<table>
  <thead>
    <tr><th>Variable</th><th>Moyenne</th><th>Ã‰cart-type</th><th>CV</th><th>InterprÃ©tation</th></tr>
  </thead>
  <tbody>
    <tr><td>Hauteur des plantes</td><td>180 cm</td><td>12 cm</td><td>(12/180) Ã— 100 = <strong>6,67%</strong></td><td>Faible variabilitÃ© relative</td></tr>
    <tr><td>Longueur des graines</td><td>1,2 cm</td><td>0,3 cm</td><td>(0,3/1,2) Ã— 100 = <strong>25,0%</strong></td><td>Forte variabilitÃ© relative</td></tr>
  </tbody>
</table>

<p>MalgrÃ© un Ã©cart-type <em>beaucoup plus petit</em> en valeur absolue, la longueur des graines est bien <strong>plus variable</strong> relativement Ã  sa moyenne.</p>

<h3>InterprÃ©tation du CV</h3>

<table>
  <thead>
    <tr><th>Plage du CV</th><th>InterprÃ©tation</th><th>Contexte typique</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>CV < 10%</strong></td><td>Faible variabilitÃ© â€” trÃ¨s homogÃ¨ne</td><td>Analyses de laboratoire, instruments de prÃ©cision</td></tr>
    <tr><td><strong>10% â‰¤ CV â‰¤ 20%</strong></td><td>VariabilitÃ© modÃ©rÃ©e â€” acceptable</td><td>Essais agronomiques, mesures biologiques</td></tr>
    <tr><td><strong>20% < CV â‰¤ 30%</strong></td><td>Forte variabilitÃ© â€” Ã  surveiller</td><td>EnquÃªtes en sciences sociales, donnÃ©es Ã©cologiques</td></tr>
    <tr><td><strong>CV > 30%</strong></td><td>TrÃ¨s forte variabilitÃ© â€” donnÃ©es hÃ©tÃ©rogÃ¨nes</td><td>Distributions de revenus, traits biologiques trÃ¨s variables</td></tr>
  </tbody>
</table>

<h3>Quand NE PAS Utiliser le CV</h3>

<table>
  <thead>
    <tr><th>Limitation</th><th>Explication</th></tr>
  </thead>
  <tbody>
    <tr><td>âš ï¸ <strong>Moyenne proche de zÃ©ro</strong></td><td>Si xÌ„ â‰ˆ 0, le CV explose vers l'infini</td></tr>
    <tr><td>âš ï¸ <strong>Ã‰chelle d'intervalle uniquement</strong></td><td>Le CV n'est valable que pour les donnÃ©es Ã  <strong>Ã©chelle de rapport</strong>. La tempÃ©rature en Â°C n'a pas de vrai zÃ©ro â€” le mÃªme jeu en Celsius et Fahrenheit donne des CV diffÃ©rents</td></tr>
    <tr><td>âš ï¸ <strong>Valeurs nÃ©gatives</strong></td><td>Si les donnÃ©es contiennent des valeurs nÃ©gatives, le CV n'a pas de sens</td></tr>
  </tbody>
</table>

<blockquote>ğŸŒ¾ <strong>Application Agronomique :</strong> Dans les essais au champ, le CV est l'indicateur standard de la prÃ©cision expÃ©rimentale. Gomez & Gomez (1984) suggÃ¨rent qu'un CV infÃ©rieur Ã  12% indique un bon contrÃ´le expÃ©rimental pour la plupart des traits culturaux, tandis qu'un CV supÃ©rieur Ã  20% signale une variation excessive nÃ©cessitant un remaniement du protocole. Les tableaux ANOVA en recherche agronomique rapportent systÃ©matiquement le CV.</blockquote>

<hr>

<h2>ğŸ”„ Comparaison ComplÃ¨te de Toutes les Mesures</h2>

<table>
  <thead>
    <tr><th>Mesure</th><th>Formule</th><th>UnitÃ©s</th><th>Utilise toutes les donnÃ©es ?</th><th>RÃ©sistant aux valeurs aberrantes ?</th><th>Meilleur usage</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>Ã‰tendue</strong></td><td>X<sub>max</sub> âˆ’ X<sub>min</sub></td><td>Identiques</td><td>âŒ ExtrÃªmes seulement</td><td>âŒ TrÃ¨s sensible</td><td>AperÃ§u rapide</td></tr>
    <tr><td><strong>EIQ</strong></td><td>Qâ‚ƒ âˆ’ Qâ‚</td><td>Identiques</td><td>âŒ 50% centraux</td><td>âœ… TrÃ¨s robuste</td><td>MÃ©diane, boÃ®tes Ã  moustaches</td></tr>
    <tr><td><strong>EMA</strong></td><td>Î£|xáµ¢ âˆ’ xÌ„| / n</td><td>Identiques</td><td>âœ…</td><td>ModÃ©rÃ©</td><td>Analyse robuste</td></tr>
    <tr><td><strong>Variance</strong></td><td>Î£(xáµ¢ âˆ’ xÌ„)Â² / (nâˆ’1)</td><td>Au carrÃ©</td><td>âœ…</td><td>âŒ Sensible</td><td>ANOVA, travail thÃ©orique</td></tr>
    <tr><td><strong>Ã‰cart-type</strong></td><td>âˆšVariance</td><td>Identiques</td><td>âœ…</td><td>âŒ Sensible</td><td>Moyenne, loi normale</td></tr>
    <tr><td><strong>CV</strong></td><td>(s / xÌ„) Ã— 100%</td><td>Sans dimension (%)</td><td>âœ…</td><td>âŒ Sensible</td><td>Comparaison inter-groupes</td></tr>
  </tbody>
</table>

<hr>

<h2>ğŸ§® Formule de Calcul Rapide de la Variance</h2>

<p>Pour le calcul Ã  la main, la <strong>formule computationnelle</strong> Ã©vite de calculer les Ã©carts un par un (Triola, 2018) :</p>

<p style="text-align:center;"><strong>sÂ² = [n(Î£xáµ¢Â²) âˆ’ (Î£xáµ¢)Â²] / [n(n âˆ’ 1)]</strong></p>

<p><strong>VÃ©rification avec nos donnÃ©es pH :</strong></p>
<p style="text-align:center;">sÂ² = [5(232,10) âˆ’ (34,0)Â²] / [5(4)] = [1160,50 âˆ’ 1156,00] / 20 = 4,50 / 20 = <strong>0,225</strong> âœ“</p>

<hr>

<h2>ğŸ”¬ Exemple Complet : Comparer Deux Traitements d'Engrais</h2>

<p>Un chercheur Ã  Batna, AlgÃ©rie, teste deux engrais azotÃ©s sur l'orge. Dix parcelles reÃ§oivent chacune le traitement A ou B, et les rendements (en q/ha) sont enregistrÃ©s :</p>

<table>
  <thead>
    <tr><th>Statistique</th><th>Traitement A</th><th>Traitement B</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>Moyenne (xÌ„)</strong></td><td>30,0 q/ha</td><td>30,0 q/ha</td></tr>
    <tr><td><strong>Ã‰tendue</strong></td><td>33 âˆ’ 27 = 6</td><td>42 âˆ’ 18 = 24</td></tr>
    <tr><td><strong>Variance (sÂ²)</strong></td><td>3,11</td><td>72,22</td></tr>
    <tr><td><strong>Ã‰cart-type (s)</strong></td><td>1,76 q/ha</td><td>8,50 q/ha</td></tr>
    <tr><td><strong>CV</strong></td><td>5,87%</td><td>28,33%</td></tr>
  </tbody>
</table>

<p><strong>InterprÃ©tation :</strong> Les deux engrais produisent le mÃªme rendement moyen â€” mais l'histoire sous la moyenne est radicalement diffÃ©rente. Le traitement A offre des rÃ©sultats homogÃ¨nes et prÃ©visibles (CV â‰ˆ 6%). Le traitement B est un pari : certaines parcelles excellent tandis que d'autres Ã©chouent (CV â‰ˆ 28%). Pour un agriculteur prudent, le traitement A est le choix Ã©vident malgrÃ© la moyenne identique. C'est la puissance de l'analyse de la dispersion.</p>

<hr>

<h2>ğŸ“ Dispersion et Forme des Distributions</h2>

<table>
  <thead>
    <tr><th>Forme de la distribution</th><th>Meilleure tendance centrale</th><th>Meilleure dispersion</th><th>Pourquoi</th></tr>
  </thead>
  <tbody>
    <tr><td><strong>SymÃ©trique (normale)</strong></td><td>Moyenne</td><td>Ã‰cart-type</td><td>Moyenne et Ïƒ caractÃ©risent entiÃ¨rement la loi normale</td></tr>
    <tr><td><strong>AsymÃ©trique</strong></td><td>MÃ©diane</td><td>EIQ</td><td>Les deux rÃ©sistent Ã  l'influence de la queue longue</td></tr>
    <tr><td><strong>DonnÃ©es contaminÃ©es</strong></td><td>Moyenne tronquÃ©e</td><td>Ã‰cart absolu mÃ©dian</td><td>Mesures robustes rÃ©sistent aux valeurs extrÃªmes</td></tr>
    <tr><td><strong>Ã‰chelles diffÃ©rentes</strong></td><td>Moyenne</td><td>Coefficient de variation</td><td>Le CV normalise la dispersion par rapport au centre</td></tr>
  </tbody>
</table>

<hr>

<h2>âš ï¸ Erreurs Courantes et IdÃ©es Fausses</h2>

<table>
  <thead>
    <tr><th>PiÃ¨ge</th><th>L'Erreur</th><th>La Correction</th></tr>
  </thead>
  <tbody>
    <tr><td>âŒ <strong>Moyenne sans dispersion</strong></td><td>Â« Le rendement moyen Ã©tait de 30 q/ha Â» â€” sans Ã©cart-type</td><td>Toujours accompagner la moyenne d'une mesure de dispersion et de n</td></tr>
    <tr><td>âŒ <strong>Comparer des Ïƒ d'Ã©chelles diffÃ©rentes</strong></td><td>Conclure que la taille (Ïƒ = 12 cm) est moins variable que le poids (Ïƒ = 8 kg)</td><td>Utiliser le CV pour les comparaisons inter-variables</td></tr>
    <tr><td>âŒ <strong>Ã‰cart-type pour donnÃ©es asymÃ©triques</strong></td><td>Rapporter moyenne Â± Ïƒ pour les revenus (trÃ¨s asymÃ©triques)</td><td>Utiliser mÃ©diane et EIQ pour les distributions asymÃ©triques</td></tr>
    <tr><td>âŒ <strong>Confondre Ïƒ et s</strong></td><td>Utiliser les formules de population (Ã· n) sur des donnÃ©es Ã©chantillonnales</td><td>Toujours utiliser n âˆ’ 1 pour les Ã©chantillons</td></tr>
    <tr><td>âŒ <strong>InterprÃ©ter la variance directement</strong></td><td>Â« La variance est 25 cmÂ² Â» â€” que signifie Â« centimÃ¨tres carrÃ©s Â» ?</td><td>Rapporter l'Ã©cart-type (5 cm) pour l'interprÃ©tabilitÃ©</td></tr>
  </tbody>
</table>

<hr>

<h2>ğŸ¯ Arbre de DÃ©cision : Choisir la Bonne Mesure</h2>

<table>
  <thead>
    <tr><th>Question</th><th>Si OUI â†’</th><th>Si NON â†’</th></tr>
  </thead>
  <tbody>
    <tr><td>Juste un aperÃ§u rapide de la dispersion totale ?</td><td>Utilisez l'<strong>Ã‰tendue</strong></td><td>â†“</td></tr>
    <tr><td>DonnÃ©es asymÃ©triques ou avec valeurs aberrantes ?</td><td>Utilisez l'<strong>EIQ</strong> (avec MÃ©diane)</td><td>â†“</td></tr>
    <tr><td>DonnÃ©es approximativement normales ?</td><td>Utilisez l'<strong>Ã‰cart-type</strong> (avec Moyenne)</td><td>â†“</td></tr>
    <tr><td>Comparer des groupes d'unitÃ©s ou de moyennes trÃ¨s diffÃ©rentes ?</td><td>Utilisez le <strong>CV</strong></td><td>â†“</td></tr>
    <tr><td>ANOVA, rÃ©gression ou dÃ©rivations thÃ©oriques ?</td><td>Utilisez la <strong>Variance</strong></td><td>Utilisez Ïƒ ou EIQ selon le cas</td></tr>
  </tbody>
</table>

<hr>

<h2>ğŸ“š RÃ©fÃ©rences</h2>

<p>Agresti, A., & Finlay, B. (2018). <em>Statistical methods for the social sciences</em> (5th ed.). Pearson.</p>

<p>Devore, J. L., & Berk, K. N. (2012). <em>Modern mathematical statistics with applications</em> (2nd ed.). Springer.</p>

<p>Freedman, D., Pisani, R., & Purves, R. (2007). <em>Statistics</em> (4th ed.). W. W. Norton & Company.</p>

<p>Gomez, K. A., & Gomez, A. A. (1984). <em>Statistical procedures for agricultural research</em> (2nd ed.). John Wiley & Sons.</p>

<p>Gorard, S. (2005). Revisiting a 90-year-old debate: The advantages of the mean deviation. <em>British Journal of Educational Studies</em>, 53(4), 417â€“430. https://doi.org/10.1111/j.1467-8527.2005.00304.x</p>

<p>Huber, P. J., & Ronchetti, E. M. (2009). <em>Robust statistics</em> (2nd ed.). Wiley.</p>

<p>Moore, D. S., McCabe, G. P., & Craig, B. A. (2021). <em>Introduction to the practice of statistics</em> (10th ed.). W. H. Freeman.</p>

<p>Pearson, K. (1896). Mathematical contributions to the theory of evolution. III. Regression, heredity, and panmixia. <em>Philosophical Transactions of the Royal Society of London, Series A</em>, 187, 253â€“318.</p>

<p>Reichel, F. (2025). On Bessel's correction: Unbiased sample variance, the bariance, and a novel runtime-optimized estimator. <em>arXiv preprint</em> arXiv:2503.22333.</p>

<p>Rothwell, P. M., et al. (2010). Prognostic significance of visit-to-visit variability, maximum systolic blood pressure, and episodic hypertension. <em>The Lancet</em>, 375(9718), 895â€“905. https://doi.org/10.1016/S0140-6736(10)60308-X</p>

<p>Triola, M. F. (2018). <em>Elementary statistics</em> (13th ed.). Pearson.</p>

<p>Tukey, J. W. (1977). <em>Exploratory data analysis</em>. Addison-Wesley.</p>

<p>Wackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2014). <em>Mathematical statistics with applications</em> (7th ed.). Cengage Learning.</p>

<p>Weisberg, H. F. (1992). <em>Central tendency and variability</em>. Sage Publications.</p>
